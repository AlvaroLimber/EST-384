---
title: "Primer Parcial (30pts)"
subtitle: "Programacion Estadística II"
author: "Lic. Alvaro Chirino Gutierrez"
date: "11/7/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pregunta 1 (10 pts)

Usando la encuesta a hogares 2018, realice de forma secuencial lo siguiente:

```{r}
library(dplyr)
rm(list=ls())
load(url("https://github.com/AlvaroLimber/EST-384/raw/master/data/eh18.Rdata"))
```

  * Seleccione al jefe/jefa del hogar de hogares que tengan al menos 1 niño/a de 5 años o menos 
  * Para la variable ingreso laboral (en logaritmo natural) del jefe del hogar construya un modelo lineal con las siguientes variables dependientes:
    + edad
    + sexo
    + número de miembros
    + número de personas de 60 años o más
    + años de educación
    + hogar con acceso a electricidad
    + servicio sanitario privado
    + hogar pobre/no pobre
    
```{r}
#jefe/a del hogar
jefe<-eh18p %>% filter(s02a_05==unique(eh18p$s02a_05)[1]) %>% select(folio,s02a_02,s02a_03,aestudio,p0,ylab)
#filtro niños/as y variables resumen del hogar
nn<-eh18p %>% mutate(nn=s02a_03<=5,miembros=sum(1),adultos60=s02a_03>=60) %>% group_by(folio) %>% summarise(nn=sum(nn),miembros=sum(miembros),adultos=sum(adultos60))
#variables en la vivienda
vv<-eh18v %>% mutate(electrico=s01a_19=="1. Si",privado=(s01a_17=="1.Usado sólo por su hogar?")) %>% select(folio,electrico,privado)
#base consolidada
jefe<-merge(jefe,nn)
jefe<-merge(jefe,vv)
#seleccion de los hogares con niños
jefe<-jefe %>% filter(nn>0)
#corrigiendo los na para la pregunta sanitario privado
jefe$privado[is.na(jefe$privado)]<-F
jefe<-jefe %>% select(-folio,-nn)
head(jefe)
```
    
  * Realice los siguientes pasos sobre el modelo
  
```{r}
# Según la naturaleza de las variables defina el modelo lineal y elimine a las no significativas ($p<0.05$)
model1<-lm(log(ylab)~.,data=jefe)
model2<-step(model1)
summary(model2)
# Realice el test de normalidad sobre los errores y comente 
library(nortest)
ee<-residuals(model2)
ad.test(ee)
lillie.test(ee)#no hay normalidad
plot(density(ee))
# Realice un test de multicolinealidad y comente
library(car)
vif(model2)
sqrt(vif(model2))>2 # no se descarta ninguna variable
# Realice un test de Homocedasticidad y comente
library(lmtest)
bptest(model2) # H0: Homocedasticidad, Por lo tanto no es homocedastico
# Incluya la interacción edad con número de miembros
model3<-lm(log(ylab) ~ s02a_02 + s02a_03 + aestudio + p0 + miembros + adultos + 
    electrico + privado+s02a_03:miembros,data=jefe)
summary(model3)
# Incluya los polinomios hasta el grado 3 para la variable edad 
model4<-lm(log(ylab) ~ s02a_02  + aestudio + p0 + miembros + adultos + 
    electrico + privado+s02a_03:miembros+poly(s02a_03,3),data=jefe)
summary(model4)
```

# Pregunta 2 (10 pts)

Usando la ENDSA para el 2008 para el corte de edad de 20 a 40 años, para la variable fumar; elabore un modelo de clasificación usando los métodos:

  * Logístico
  * Árbol de clasificación
  * Naive Bayes

Considere al menos 10 covariables para la elaboración de los métodos. Comente el mejor método de clasificación, justifique su respuesta.

Solución,

```{r,message=F,warning=F}
rm(list=ls())
load(url("https://github.com/AlvaroLimber/EST-384/raw/master/data/endsa.RData"))
#seleccionando el año y la edad
endsa<-endsa %>% filter(year==2008 & edad>=20 & edad<=40)
#la variable fumar para el modelo
endsa<-endsa %>% rename(fuma=ae09)
#seleccionando las 10 variables para la clasificación
endsa<-endsa %>% select(fuma,area,edad,sexo,ae03:ae08,ant01)
#aplicando los métodos
endsa$fuma<-endsa$fuma=="Si"
#solo valores validos
endsa<-na.omit(endsa)
index<-sample(1:2,nrow(endsa),replace = T,prob=c(0.7,0.3))
trainBD<-endsa[index==1,]
testBD<-endsa[index==2,]
# Logístico
m1<-glm(fuma~.,data=trainBD,family = binomial(link="logit"))
m2<-step(m1)
clase<-predict(m2,testBD,type="response")>0.5
t_logit<-table(clase,testBD$fuma)
# Árbol de clasificación

trainBD$fuma<-factor(trainBD$fuma,levels = c(T,F),c("si","no"))
testBD$fuma<-factor(testBD$fuma,levels = c(T,F),c("si","no"))
library(rpart)
mod1<-rpart(fuma~.,data=trainBD)
library(rpart.plot)
rpart.plot(mod1)
clase<-predict(mod1,testBD,type = "class")
t_cart<-table(clase,testBD$fuma)
# Naive Bayes
library(e1071)
model1<-naiveBayes(fuma~.,data=trainBD)
clase<-predict(model1,testBD,type = "class")
t_naive<-table(clase,testBD$fuma)
#identificando al mejor
library(caret)
confusionMatrix(t_logit)
confusionMatrix(t_cart)
confusionMatrix(t_naive)
#El método CART es mejor
```

# Pregunta 3 (10 pts)

Seleccione solo una de las siguientes fuentes de información:

1. Usando la API de twitter genere una base de datos de los 1000 últimos post de la palabra "coronavirus", sin retweets, en español.
2. Colección de 3 tesis en pdf del enlace \url{https://repositorio.umsa.bo/handle/123456789/7292}

A partir de esta base realice de forma secuencial:

  * Establezca el Corpus
  * Ponga las palabras en mayúsculas
  * Elimine los números y la puntuación
  * Elimine los stopwords en español e incluya 3 palabras definidas por usted para su eliminación
  * Realice una nube de palabras y comente los hallazgos
  * Realice el análisis de sentimiento y grafique 2 figuras; una para las ocho emociones y otra para los sentimientos positivos y negativos


Solución,

```{r}
rm(list=ls())
library(rtweet)
library(tm)
library(wordcloud2)
tw<-search_tweets("coronavirus",n=1000,include_rts = F,lang="es")
# Establezca el Corpus
docs<-VCorpus(VectorSource(tw$text))
# Ponga las palabras en mayúsculas
# Elimine los números y la puntuación
# Elimine los stopwords en español e incluya 3 palabras definidas por usted para su eliminación
docs<-docs %>% tm_map(content_transformer(toupper)) 
docs<- docs %>% tm_map(removeNumbers) %>% tm_map(removePunctuation) 
docs <- tm_map(docs,removeWords,c(stopwords("sp"),"QUE","POR","DEL"))
# Realice una nube de palabras y comente los hallazgos
tdm<-TermDocumentMatrix(docs)
matrix <- as.matrix(tdm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)    
wordcloud2(df)
#al poner en mayusculas el stopwords no reconoce las palabras 

# Realice el análisis de sentimiento y grafique 2 figuras; una para las ocho emociones y otra para los sentimientos positivos y negativos
library(syuzhet)
library(ggplot2)
ss<-get_nrc_sentiment(tw$text,language = "spanish")
barplot(apply(ss[1:8],2,sum),horiz = T,las=1)
barplot(apply(ss[9:10],2,sum),horiz = T,las=1)
```


# Pregunta opcional (5 pts)

Usando la librería syuzhet incorpore las siguientes 4 palabras en el léxico nrc:

  * racista, negative, 1
  * patético, anger,1
  * roban, anger,1
  * lacra, anger,1

Adapte la función para que el análisis de sentimiento incluya estas palabras. Verifique el funcionamiento con la frase:


"Esa persona es racista, patético y una lacra. otros roban a las personas"

```{r,echo=F}
rm(list=ls())
source("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\code\\ejemplo.R")
```

Ejemplo en R

```{r,warning=F,message=F}
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
#resultado actual
library(syuzhet)
get_nrc_sentiment(frase,language = "spanish")
#resultado esperado
ejemplo(frase,language = "spanish")
```

Solución, 

```{r}
ejemplo<-function (char_v, cl = NULL, language = "english") 
{
  #char_v<-frase
  #lexico
  aux<-data.frame(rbind(c("spanish","racista", "negative",1),
                        c("spanish","patético", "anger",1),
                        c("spanish","roban", "anger",1),
                        c("spanish","lacra", "anger",1)))
  aux$X4<-as.numeric(aux$X4)
  names(aux)<-c("lang","word","sentiment","value")
  ww<-syuzhet::get_sentiment_dictionary("nrc",language = "spanish")
  nrc_bol<-rbind(ww,aux)
  #####################
  if (!is.character(char_v)) 
    stop("Data must be a character vector.")
  if (!is.null(cl) && !inherits(cl, "cluster")) 
    stop("Invalid Cluster")
  lexicon <- dplyr::filter_(nrc_bol, ~lang == language)
  word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
  if (is.null(cl)) {
    nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
  }
  else {
    nrc_data <- parallel::parLapply(cl = cl, word_l, lexicon = lexicon, 
                                    get_nrc_values)
  }
  result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
  my_col_order <- c("anger", "anticipation", "disgust", "fear", 
                    "joy", "sadness", "surprise", "trust", "negative", "positive")
  result_df[, my_col_order]
}
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
ejemplo(frase,language = "spanish")
```


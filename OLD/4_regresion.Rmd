[comment]: <> (Machine Learning with R Cookbook, capitulo 4)
[comment]: <> (Torgo, 4.6)
# Regresión

$$y=f(x_1,x_2, \ldots)$$

  * $y$ Variable de resultado, dependiente, solo tenemos a una $y$. 
  * $x_1, x_2, \ldots$, variables de control, independientes.
  
 A partir de estas variables:
 
  * ¿Cuál es la relación de $x$ sobre $y$?
    + Lineal  

$$y_i=\beta_0+\beta_1 x_{i1}+\beta_2 x_{i2}+\ldots+\epsilon_i$$
$$E[y_i]=E[\hat{\beta}_0+\hat{\beta}_1 x_{i1}+\hat{\beta}_2 x_{i2}+\ldots]$$

$$\frac{dy}{d x_1}= \beta_1$$


> Nota: Diferenciar que la regresión busca establecer relaciones basadas en los datos y no asi un proceso causal.

  + Polinomial
  + Etc; No lineal,
    
  * Conocer la naturaleza de $y$ y las variables $x$
    + $Y$ es cuanti (real), $X$ mixtas. (Modelos lineales, MCO)
    + $Y$ es cuanti (discreta >= 0), $X$ cuanti. (Poisson)
    + $Y$ es cuali nominal binario, $X$ mixtas. (LOGIT/PROBIT)
    + $Y$ es cuali ordinal, $X$ mixtas. (Logit/probit ordenados)

## Regresión lineal

1. Base datos lista para el modelo (Unidad de investigación)
2. Establecer la relación interés
3. Definir el modelo de interés
4. Optimizar el modelo
5. Validar el modelo
6. Predecir a partir del modelo


### Paso 1: Base de datos

Dos poblaciones de estudio:

  * Personas de 18 a 35 años ocupadas, EH-2019 (bd1) 
  * Personas de 18 años o más, jefes de hogar y ocupados, EH-2018 (bd2)

```{r,eval=F}
library(dplyr)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\data\\eh19.Rdata")
bd1<-eh19p %>% filter(s02a_03>=18 & s02a_03<=35 & ocupado=="Si") %>% select(s02a_02,s02a_03,aestudio,tothrs,ylab,ynolab,factor,estrato, upm,area,permanente,cob_op)

load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\data\\eh18.Rdata")
bd2<-eh18p %>% filter(s02a_03>=18 & s02a_05=="1.JEFE O JEFA DEL HOGAR" & ocupado=="Si") %>% select(s02a_02,s02a_03,aestudio,tothrs,ylab,ynolab,factor,estrato, upm,area,permanente,cob_op)
```

### Paso 2: Establecer la relación de interés.

  * $Y$ Ingreso laboral puede ser un buena opción
  * $X$ el resto, pueden ser basadas en un modelo teórico o buscadas a partir de un proceso de minería de datos

$$IngresoLaboral=f(edad,sexo,educación,...)$$
Para definir el vector de covariables $X$, una práctica recomendada es identificar variables desde el unidad de análisis hacia otras unidades agregadas. 


### Paso 3: Definir el modelo a utilizar

OLS, MCO. Modelos lineales

```{r,eval=F}
# regresión lineal simple y=f(x)
m1_1<-lm(ylab~aestudio,data=bd1)
m1_2<-lm(ylab~aestudio,data=bd2)
m1_1
m1_2
```

$$ylab_i=\beta_0+\beta_1 educacion_i+\epsilon_i$$
* Para personas de 18 a 35 (2019)

$$E[ylab_i]=1231.7-136.7*educacion_i$$
* Para personas de 18 años o más (jefes de hogar) (2018)

$$E[ylab_i]=1241.9-194.7*educacion_i$$
```{r,eval=F}
plot(bd1$aestudio,bd1$ylab)
abline(m1_1,col="red",lwd=3)

summary(m1_1)

plot(bd2$aestudio,bd2$ylab)
abline(m1_2,col="red",lwd=3)
summary(m1_2)
```

```{r,eval=F}
#en los betas
coefficients(m1_1)
coefficients(m1_2)

confint(m1_1,level=0.95)
confint(m1_2,level=0.95)
```

### Paso 4: Optimizar el modelo

```{r,eval=F}
m2_1<-lm(log(ylab)~aestudio,data=bd1)
m2_2<-lm(log(ylab)~aestudio,data=bd2)
summary(m2_1)


plot(bd2$aestudio,log(bd2$ylab))
abline(m2_2,col="red",lwd=3)
summary(m2_2)
```

$$E[log(ylab_i)]=6.83-0.091*educacion_i$$
```{r,eval=F}
m3_1<-lm(log(ylab)~.,data=bd1[,-c(7,8,9,11:12)])
m3_2<-lm(log(ylab)~.,data=bd2[,-c(7,8,9,11:12)])

summary(m3_1)
summary(m3_2)

#stepwise
m4_1<-step(m3_1)
m4_2<-step(m3_2)

summary(m4_1)
summary(m4_2)
```

Nota: Se debe tener en cuenta siempre la fuente de la información y el tipo de las variables.

```{r,eval=FALSE}
barplot(table(bd1$aestudio))

m5_1<-lm(log(ylab)~ factor(aestudio)+s02a_02+s02a_03+tothrs+area,data=bd1)
m5_2<-lm(log(ylab)~ factor(aestudio)+s02a_02+s02a_03+tothrs+area,data=bd2)
summary(m5_1)
summary(m5_2)

##########################
bd2$hombre<-bd2$s02a_02=="1.Hombre"
summary(lm(log(ylab)~ factor(aestudio)+hombre+s02a_03+tothrs+area,data=bd2))
##########################

#estamos suponiendo una relación lineal
#las relaciones que encontramos son a nivel de la muestra
#para hacer inferencia el mejor camino es la librería survey
summary(lm(log(ylab)~ factor(aestudio)+s02a_02+s02a_03+tothrs+area,data=bd2))#MCO,OLS

summary(lm(log(ylab)~ factor(aestudio)+s02a_02+s02a_03+tothrs+area,data=bd2,weights = factor))#MCP
```

### Paso 5: Validar el modelo

```{r,eval=F}
#Supuestos del modelo
## los errores se distribuyen normal(media=0,varianza=constante)
### heterocedasticidad

## Independencia entre los X del modelo
### multicolinealidad

model<-m5_2

# los errores se distribuyen normal
par(mfrow=c(2,2))
plot(model)
dev.off()
#errores
ee<-residuals(model)

plot(density(ee))
points(density(rnorm(100000,mean(ee),sd(ee))),type="l",col="red")
#prueba de normalidad
#H0 x ~ normal()
library(normtest)
library(nortest)

ad.test(ee)
lillie.test(ee)


bd2[6697,]
bd2[7920,]
bd2[1280,]

boxplot(bd2$ylab)

#limitar los datos hasta el percentil 
punto<-c(0.05,0.95)

z<-quantile(bd2$ylab,punto,na.rm=T)
z

bd2<-bd2 %>% filter((ylab<z[2] & ylab>z[1]))

plot(density(bd2$ylab))
boxplot(bd2$ylab)
#definiendo el modelo sin atípicos
model1<-lm(log(ylab)~ factor(aestudio)+s02a_02+s02a_03+tothrs+area,data=bd2)

summary(model1)

ee1<-residuals(model1)
plot(density(ee1))
points(density(rnorm(100000,mean(ee1),sd(ee1))),type="l",col="red")

ad.test(ee1)
lillie.test(ee1)
ks.test(ee1,"pnorm",mean(ee1),sd(ee1))#kolmogorov Smirnofv

plot(model1)

# Distancia de Cook
cooks.distance(model1)

plot(density(cooks.distance(model1)))
cc<-cooks.distance(model1)


bd3<-bd2[cc<quantile(cc,0.90),]
model3<-lm(log(ylab)~s02a_03+aestudio+s02a_02+area,data=bd3)
summary(model3)
plot(model3)
plot(density(cooks.distance(model3)))


ad.test(residuals(model3))
lillie.test(residuals(model3))

plot(density(residuals(model3)))
curve(dnorm(x,mean(residuals(model3)),sd(residuals(model3))),add=T,col="red")

#ajustando polinomios
bd3<-na.omit(bd3)
model4<-lm(log(ylab)~poly(s02a_03,2)+factor(aestudio)+s02a_02+poly(tothrs,3)+area,data=bd3)
summary(model4)

ad.test(residuals(model4))
## interacciones entre variables
model5<-lm(log(ylab)~poly(s02a_03,2)+factor(aestudio)+s02a_02+area+s02a_02:aestudio+area:aestudio+tothrs+I(tothrs^4),data=bd3)
summary(model5)
ad.test(residuals(model5))

#trabajando sobre los valores atípicos desde R
library(MASS)
modela<-rlm(ylab~s02a_02+s02a_03+area,data=bd3)
modelb<-lm(ylab~s02a_02+s02a_03+area,data=bd3)
summary(modela)
summary(modelb)
ad.test(residuals(model))
# Colinealidad (X1=f(X2)
library(car)
vif(model3)
sqrt(vif(model3))>2 ##Variance Inflation Factors
# Verificar si la varianza es constante (homocedástico) o no (heterocedástico)
library(lmtest)
bptest(model3) # H0: Homocedasticidad
bptest(model4)
#https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test

#corrigiendo 
library(rms)
model1 = ols(log(ylab)~s02a_02+s02a_03+aestudio+area,data=bd3,x=T,y=T)
bptest(model1)
aux<-robcov(model1)

aux
# H0: Homocedasticidad, implica que los EE de B no son los correctos
```


### Paso 6: Predicir a partir del modelo

$$\hat{y_i}=\hat{\beta_0}+\sum_{i=1}^p \hat{\beta_i} x_i$$

```{r,eval=F}
test<-bd3
yest<-predict(model3,test)
plot(log(bd3$ylab),yest)
plot(bd3$ylab,exp(yest))
```

Nota: 

$$y=\beta_0+\beta_1x_1+\beta_2 x_2+\beta_3 x_1x_2 $$
$$\frac{d y}{dx_1}=\beta_1+\beta_3 x_2$$

## Probit y Logit

Estrategia, llevar valores binarios a valores continuos. Mediante una función de enlace ($F(Y)$).

$$F(Y)=Y'=X \beta +\epsilon$$

Probit:

$$Y=\Phi (X \beta +\epsilon)$$
$$\phi^{-1}(Y)=X \beta +\epsilon$$
$$Y'=X \beta +\epsilon$$

El enlace $F(Y)=\Phi^{-1}(Y)$, es conocida como probit.


Logit:

$$logit(Y)=log(\frac{Y}{1-Y})=X\beta+\epsilon$$

$$Y=\frac{e^{X\beta+\epsilon}}{1+e^{X\beta+\epsilon}}$$

### En R:

Definir o plantear un modelo de relación $y=f(x)$ donde la variable $y$ sea de tipo binaria $(0,1)$.

$$y_{pobreza}=f(x_1,x_2,\ldots)$$

```{r,eval=F}
library(dplyr)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\data\\eh18.Rdata")
#### Pobreza a nivel de ... (hogares/persona)

#definir a y (0/1)
eh18p<-eh18p %>% mutate(pobreza=(pext0=="Pobre extremo"))
table(eh18p$pobreza)


mod1<-glm(pobreza~aestudio+s02a_02,data=eh18p,family = binomial(link="probit"))
mod2<-glm(pobreza~aestudio+s02a_02,data=eh18p,family = binomial(link="logit"))

mod3<-glm(pobreza~aestudio+s02a_02+s02a_03+ylab,data=eh18p,family = binomial(link="logit"))




summary(mod1)
summary(mod2)
#ajuste
library(DescTools)
PseudoR2(mod1)
PseudoR2(mod2)

#score probabilidades
pres<-predict(mod1,eh18p,type="response")
lres<-predict(mod2,eh18p,type="response")

predict(mod1,eh18p[1,c("aestudio","s02a_02")],type="response")

plot(density(lres,na.rm=T))
points(density(pres,na.rm=T),col="red",type="l")
points(density(pres),type = "l",col="red")

#efectos marginales
library(mfx)
probitmfx(pobreza~I(ylab/1000)+aestudio+s02a_02,data=eh18p)

logitmfx(pobreza~factor(aestudio)+s02a_02,data=eh18p)

#comparando
library(memisc)
mtable(mod1,mod2,mod3,summary.stats="AIC")

library(survey)
?svyglm()

#### enfermades crónicas 
aux<-levels(eh18p$s04a_01a)
eh18p<-eh18p %>% mutate(diabetes=(s04a_01a==aux[1] | s04a_01b==aux[1]),corazon=(s04a_01a==aux[4] | s04a_01b==aux[4]),hiper=(s04a_01a==aux[10] | s04a_01b==aux[10]))
eh18p$diabetes<-(eh18p$diabetes==T); eh18p$diabetes[is.na(eh18p$diabetes)]<-F
eh18p$corazon<-(eh18p$corazon==T); eh18p$corazon[is.na(eh18p$corazon)]<-F
eh18p$hiper<-(eh18p$hiper==T); eh18p$hiper[is.na(eh18p$hiper)]<-F
eh18p$cronicas<-(eh18p$diabetes+eh18p$corazon+eh18p$hiper)
#modelo para las enfermedades crónicas
eh18p$cronicas<-(eh18p$cronicas!=0)
#probit logit
logit<-glm(cronicas~s02a_02+s02a_03,data=eh18p,family = binomial(link="logit"))
probit<-glm(cronicas~s02a_02+s02a_03,data=eh18p,family = binomial(link="probit"))
lineal<-lm(cronicas~s02a_02+s02a_03,data=eh18p)
#resumen
summary(logit)
summary(probit)
summary(lineal)
#score probabilidades
lres<-predict(logit,eh18p,type="response")
pres<-predict(probit,eh18p,type="response")
plot(density(lres))
points(density(pres),type = "l",col="red")
#efectos marginales
library(mfx)
probitmfx(cronicas~s02a_02+s02a_03,data=eh18p)
logitmfx(cronicas~s02a_02+s02a_03,data=eh18p)
#ajuste
library(DescTools)
PseudoR2(logit)
PseudoR2(probit)
summary(lineal)
#comparando
library(memisc)
mtable(logit,probit,lineal)
```

```{r,eval=F}
summary(glm(cronicas~s02a_02+s02a_03,data=eh18p))
summary(lm(cronicas~s02a_02+s02a_03,data=eh18p))
```
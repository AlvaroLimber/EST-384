# Clasificación

Pasos sugeridos

  1. Preparar la base de datos; base de entrenamiento (trainbd) y de testeo (testbd). 70/30
  2. Definir el modelo de clasificación
    * Regresión logística (logit)
    * Árbol de clasificación (CART)
    * Naive bayes

Base de datos, se empleara la base de datos de covid de México.

```{r}
library(dplyr)
covid<-read.csv("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\data\\covid_mx\\200627COVID19MEXICO.csv",sep=",",na.strings = c(99,98))

object.size(covid)/10^6

vv<-c("SEXO","FECHA_DEF","NEUMONIA","EDAD","HABLA_LENGUA_INDIG","DIABETES","EPOC","ASMA","INMUSUPR","HIPERTENSION","OTRA_COM","CARDIOVASCULAR","OBESIDAD","RENAL_CRONICA","TABAQUISMO","RESULTADO")

covid<-covid %>% select(vv)
#Descripción 
library(Hmisc)
describe(covid)

Hmisc::describe(covid)
#variable muerte
covid<-covid %>% mutate(muerte=(FECHA_DEF!="9999-99-99")) %>% select(-FECHA_DEF) 
# valores perdidos
covid<-na.omit(covid)
```

## Logit/Probit

  * Se usan para realizar clasificaciones basadas en probabilidades
  * Las clasificaciones son del tipo 1/0 
  * Existen variaciones para clasificar considerando más grupos, empleando el logit y probit ordenado.
  
### Pasos

  0. Identificar la variable (1/0) que se requiere clasificar, definir covariables para construir el modelos
  
```{r}
table(covid$muerte)## clasificación (Y)
table(covid$RESULTADO)
prop.table(table(covid$muerte))
##################################################
#a factor (X)
##################################################
#sexo
covid$SEXO<-factor(covid$SEXO,levels=1:2,labels=c("Mujer","Hombre"))
#resultado
covid$RESULTADO<-factor(covid$RESULTADO,levels = 1:3,labels=c("COVID +","COVID -","COVID pendiende"))

covid2<-covid#para cart

#si/no
aux<-c("NEUMONIA","HABLA_LENGUA_INDIG","DIABETES","EPOC","ASMA","INMUSUPR","HIPERTENSION","OTRA_COM","CARDIOVASCULAR","OBESIDAD","RENAL_CRONICA","TABAQUISMO")
for(i in aux){
  covid[[i]]<-covid[[i]]==1
}
str(covid)
## Bases: trainbd, testbd
set.seed(123)
index = sample(1:2, nrow(covid), replace = TRUE, prob=c(0.7, 0.3))
prop.table(table(index))
trainbd<-covid %>% filter(index==1)
testbd<-covid %>% filter(index==2)
```
  
  1. Especificar el modelo (logit/probit)
  
```{r}
m1<-glm(muerte~.,data=trainbd,family = binomial(link="logit"))
```

  2. Identificar las variables significativas
  3. Construir el modelo con variables significativas

```{r}
summary(m1)
m2<-step(m1)
summary(m2)
```
  
  4. Predecir la clase de pertenencia en la base de test ($prob>0.5$)
  
```{r}
clase<-predict(m2,testbd,type="response")>0.5
```

  5. Observar la clasificación dada en base a la probabilidad fijada
  
```{r}
table(clase)
prop.table(table(clase))
```

  
  6. Comparar lo observado y lo predicho (testbd)
  
```{r}
table(testbd$muerte,clase)
```

  7. Generar la matriz de confusión (librería caret)
  
```{r}
library(caret)
confusionMatrix(table(testbd$muerte,clase))

t1<-table(testbd$muerte,clase)
t1
sum(diag(t1))/sum(t1)

```

Efectos marginales

```{r}
library(mfx)
info<-logitmfx(formula(m2),data=testbd)
barplot(info$mfxest[,1],horiz = T,las=1,cex.names = 0.5,xlim=c(-0.1,0.1),pos=-0.02)
```

## Arboles de clasificación (CART)

El método CART uso condiciones basadas en cortes sobre covariables para realizar la clasificación (predicción) de una clase. El proceso de clasificación comienza desde el nodo raíz del árbol; en cada nodo, el proceso verificará si el valor de entrada debe continuar de forma recursiva hacia la sub-rama derecha o izquierda de acuerdo con la condición de división, y se detiene al encontrar cualquier **nodo hoja** (terminal) del árbol de decisión.

### Pasos

Crear el modelo de clasificación

  1. Cargar la librería rpart
  
```{r}
#install.packages("rpart")
library(rpart)
```

  2. Usar la función rpart para construir el modelo de clasificación
  
```{r}
covid2$muerte<-factor(covid2$muerte,c(T,F),labels = c("Muerte","No muerte"))
#si/no
aux<-c("NEUMONIA","HABLA_LENGUA_INDIG","DIABETES","EPOC","ASMA","INMUSUPR","HIPERTENSION","OTRA_COM","CARDIOVASCULAR","OBESIDAD","RENAL_CRONICA","TABAQUISMO")
for(i in aux){
  covid2[[i]]<-factor(covid2[[i]],1:2,c("SI","NO"))
}
str(covid2)
## Bases: trainbd, testbd
set.seed(123)
index = sample(1:2, nrow(covid2), replace = TRUE, prob=c(0.7, 0.3))
prop.table(table(index))
trainbd<-covid2[index==1,]
testbd<-covid2[index==2,]

mod1<-rpart(muerte~.,data=trainbd)

```
  3. Explorar los nodos creados por rpart
  
```{r}
mod1
```

  4. Examinar los parámetros del árbol con printcp
  
```{r}
printcp(mod1)
```

  5. Usar el comando plotcp para explorar los parámetros de forma gráfica
  
```{r}
plotcp(mod1)
```

  6. Usar la función summary para para examinar el modelo
  
```{r}
summary(mod1)
```
  

Visualizar el árbol

  7. Usar la función plot y text(,all=T, n=T)
  
```{r}
plot(mod1)
text(mod1,all=T,use.n=T)
#install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(mod1)
```

  8. Ajustes en el layout plot(...,uniform=TRUE, branch=0.6, margin=0.1)
  
```{r}
plot(mod1,uniform=T, branch=1, margin=0.1)
text(mod1,all=T,use.n=T)
```
  
Predicción de la clasificación

  9. predict(..., testbd, type="class"), predicción sobre la base de test

```{r}
clase<-predict(mod1,testbd,type = "class")
```

  10. Elaborar una tabla de contingencia de la clasificación
  
```{r}
table(clase,testbd$muerte)
```
  
  11. Emplear el comando confusionMatrix sobre la tabla del paso anterior, para evaluar la calidad de la clasificación. Mcnemar's Test H0: $ij=ji$
  
```{r}
library(caret)
confusionMatrix(table(clase,testbd$muerte))
```
  
### Proceso de pruning (podado) 
El objetivo es eliminar variables redundantes y crear un modelo de clasificación mas robusto

Pasos:

  1. Encuentre el valor mínimo en cross-validation error. (xerror)
  
```{r}
min(mod1$cptable[,"xerror"])
```

  2. Encontrar el registro que contiene el valor del anterior paso. (which.min, cptable)
  

```{r}
which.min(mod1$cptable[,"xerror"])
```

  3. Obtenga el "cost complexity parameter" del valor mínimo encontrado (CP)
  
```{r}
mod1.cp<-mod1$cptable[2,"CP"]
```

  4. Realizar el podado con la función prune, empleando el modelo original y el CP del valor mínimo en xerror (paso anterior) 
  
```{r}
mod1.prune<-prune(mod1,cp=mod1.cp)
```

  5. Visualice el nuevo árbol

```{r}
rpart.plot(mod1.prune)
```
  

  6. Realice la predicción a partir del árbol podado
  
```{r}
clase<-predict(mod1.prune,testbd,type = "class")
```


  7. Evalúe los resultados con la matriz de confusión
  
```{r}
confusionMatrix(table(clase,testbd$muerte))
```
  

## Naive Bayes
Es un modelo basado en probabilidad, su base teórica aplica el teorema de Bayes (fuerte supuesto de independencia).

>nota 

$$P(muerte/edad,neumonia, ...)<>P(\sim muerte/edad,neumonia,...)$$

$$P(C/X)=\frac{P(C)*P(X/C)}{P(X)}$$
  * $P(C/X)$ Probabilidad Posterior 
  * $P(C)$ Probabilidad a Priori
  * $P(X/C)$ Verosimilitud
  * $P(X)$ Marginal

Si se tiene varios predictores ($X$) se supone independencia, esto es:

$$P(C/X) =  \frac{P(X_1/C)*P(X_2/C)*\ldots *P(X_n/C)*P(C)}{P(X)}$$
Pasos, 

  1. Cargar la librería e1071 y emplear la función naiveBayes para construir el clasificador
  
```{r}
library(e1071)
mod1<-naiveBayes(muerte~.,data=trainbd)
```

  2. Explorar los resultados
  
```{r}
mod1
```

  3. Predecir los resultados en la base de testeo
  
```{r}
clase<-predict(mod1,testbd,type = "class")
```

  4. Realizar la matriz de confusión

```{r}
confusionMatrix(table(clase,testbd$muerte))
```


## Ejercicios.

1. Usando la ENDSA para un año en particular, defina clases de violencia en base a las variables de violencia y aplique los métodos de clasificación con las variables que considere relevante.
2. Usando la Encuesta a hogares, para la clase nivel de educación (ninguno, primaria, secundaria, superior) aplique los métodos de clasificación considerando las variables relevantes. 


[comment]: <> (Machine Learning with R Cookbook, capitulo 4)
[comment]: <> (Torgo, 4.6)
# Regresión

$$y=f(x_1,x_2, \ldots)$$

  * $y$ Variable de resultado, dependiente, solo tenemos a una $y$. 
  * $x_1, x_2, \ldots$, variables de control, independientes.
  
 A partir de estas variables:
 
  * ¿Cuál es la relación de $x$ sobre $y$?
    + Lineal  

$$y_i=\beta_0+\beta_1 x_{i1}+\beta_2 x_{i2}+\ldots+\epsilon_i$$
$$E[y_i]=E[\hat{\beta}_0+\hat{\beta}_1 x_{i1}+\hat{\beta}_2 x_{i2}+\ldots]$$

$$\frac{dy}{d x_1}= \beta_1$$


> Nota: Diferenciar que la regresión busca establecer relaciones basadas en los datos y no asi un proceso causal.

  + Polinomial
  + Etc; No lineal,
    
  * Conocer la naturaleza de $y$ y las variables $x$
    + $Y$ es cuanti (real), $X$ mixtas. (Modelos lineales, MCO)
    + $Y$ es cuanti (discreta >= 0), $X$ cuanti. (Poisson)
    + $Y$ es cuali nominal binario, $X$ mixtas. (LOGIT/PROBIT)
    + $Y$ es cuali ordinal, $X$ mixtas. (Logit/probit ordenados)

## Regresión lineal

1. Base datos lista para el modelo (Unidad de investigación)
2. Establecer la relación interés
3. Definir el modelo de interés
4. Optimizar el modelo
5. Validar el modelo
6. Predecir a partir del modelo


### Paso 1: Base de datos

Dos poblaciones de estudio:

  * Personas de 18 a 35 años ocupadas, EH-2019 (bd1) 
  * Personas de 18 años o más, jefes de hogar y ocupados, EH-2018 (bd2)

```{r,eval=F}
library(dplyr)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\data\\eh19.Rdata")
bd1<-eh19p %>% filter(s02a_03>=18 & s02a_03<=35 & ocupado=="Si") %>% select(s02a_02,s02a_03,aestudio,tothrs,ylab,ynolab,factor,estrato, upm,area,permanente,cob_op)

load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\data\\eh18.Rdata")
bd2<-eh18p %>% filter(s02a_03>=18 & s02a_05=="1.JEFE O JEFA DEL HOGAR" & ocupado=="Si") %>% select(s02a_02,s02a_03,aestudio,tothrs,ylab,ynolab,factor,estrato, upm,area,permanente,cob_op)
```

### Paso 2: Establecer la relación de interés.

  * $Y$ Ingreso laboral puede ser un buena opción
  * $X$ el resto, pueden ser basadas en un modelo teórico o buscadas a partir de un proceso de minería de datos

$$IngresoLaboral=f(edad,sexo,educación,...)$$
Para definir el vector de covariables $X$, una práctica recomendada es identificar variables desde el unidad de análisis hacia otras unidades agregadas. 


### Paso 3: Definir el modelo a utilizar

OLS, MCO. Modelos lineales

```{r,eval=F}
# regresión lineal simple y=f(x)
m1_1<-lm(ylab~aestudio,data=bd1)
m1_2<-lm(ylab~aestudio,data=bd2)
m1_1
m1_2
```

$$ylab_i=\beta_0+\beta_1 educacion_i+\epsilon_i$$
* Para personas de 18 a 35

$$E[ylab_i]=1231.7-136.7*educacion_i$$
* Para personas de 18 años o más (jefes de hogar)

$$E[ylab_i]=1241.9-194.7*educacion_i$$
```{r,eval=F}
plot(bd1$aestudio,bd1$ylab)
abline(m1_1,col="red",lwd=3)

summary(m1_1)

plot(bd2$aestudio,bd2$ylab)
abline(m1_2,col="red",lwd=3)
summary(m1_2)
```

```{r,eval=F}
#en los betas
coefficients(m1_1)
coefficients(m1_2)

confint(m1_1,level=0.95)
confint(m1_2,level=0.95)

#mejorar el modelo


```

### Paso 4: Optimizar el modelo

```{r,eval=F}
m5<-lm(log(ylab)~.,data=bd[,-c(7,8,9,11)])
summary(m5)
m6<-step(m5)
summary(m6)
#un ejemplo de laboratorio
bd2<-as.data.frame(matrix(rnorm(1000),ncol = 8))
names(bd2)[1]<-"y"
bd2$x<-bd2$y+runif(125)
plot(bd2$x,bd2$y)
plot(bd2)
p1<-lm(y~.,data=bd2)
summary(p1)
p2<-step(p1)
summary(p2)
```

Nota: Se debe tener en cuenta siempre la fuente de la información

```{r,eval=FALSE}
summary(m4)
summary(lm(ylab~factor(aestudio)+s02a_02+s02a_03,data=bd))
summary(lm(log(ylab)~factor(aestudio)+s02a_02+s02a_03,data=bd))
#estamos suponiendo una relación lineal
#las relaciones que encontramos son a nivel de la muestra
#para hacer inferencia el mejor camino es la libreria survey
summary(lm(log(ylab)~factor(aestudio)+s02a_02+s02a_03,data=bd))#MCO,OLS
summary(lm(log(ylab)~factor(aestudio)+s02a_02+s02a_03
           ,weights = factor ,data=bd))#MCP
```


### Paso 5: Validar el modelo

```{r,eval=F}
#Supuestos del modelo
## los errores se distribuyen normal(media=0, varianza=constante)
## Independencia entre los X del modelo
# los errores se distribuyen normal
model<-lm(log(ylab)~s02a_03+aestudio+tothrs+ynolab+s02a_02+area+cob_op,data=bd)
summary(model)

par(mfrow=c(2,2))
plot(model)
dev.off()
#errores
ee<-residuals(model)
plot(density(ee))
#prueba de normalidad
#H0 x ~ normal()
library(normtest)
library(nortest)
ad.test(ee)
lillie.test(ee)
boxplot(bd$ylab)
#La normalidad de los errores
plot(density(ee))
curve(dnorm(x,mean(ee),sd(ee)),add=T,col="red")
#limitar los datos hasta el percentil 
punto<-c(0.01,0.90)
puntonl<-c(0.99)
z<-quantile(bd$ylab,punto,na.rm=T)
znl<-quantile(bd$ynolab,puntonl,na.rm=T)
znl
bd2<-bd %>% filter((ylab<z[2] & ylab>z[1]))
boxplot(bd2$ynolab)

#definiendo el modelo sin atípicos
model1<-lm(log(ylab)~s02a_03+aestudio+tothrs+s02a_02+area,data=bd2)
summary(model1)
boxplot(bd2$ylab)

ee1<-residuals(model1)
ad.test(ee1)
lillie.test(ee1)
ks.test(ee1,"pnorm",mean(ee1),sd(ee1))#kolmogorov Smirnofv

plot(density(ee1))
curve(dnorm(x,mean(ee1),sd(ee1)),add=T,col="red")
plot(model1)

# Distancia de Cook
plot(cooks.distance(model1))
cc<-cooks.distance(model1)
bd3<-bd2[cc<quantile(cc,0.90),]
model3<-lm(log(ylab)~s02a_03+aestudio+s02a_02+area,data=bd3)
summary(model3)
ad.test(residuals(model3))
lillie.test(residuals(model3))

plot(density(residuals(model3)))
curve(dnorm(x,mean(residuals(model3)),sd(residuals(model3))),add=T,col="red")
plot(model3)
plot(cooks.distance(model3))
#ajustando polinomios
bd3<-na.omit(bd3)
model4<-lm(log(ylab)~poly(s02a_03,2)+poly(aestudio,3)+s02a_02+area,data=bd3)
summary(model4)

ad.test(residuals(model4))
## interacciones entre variables
model5<-lm(log(ylab)~poly(s02a_03,2)+poly(aestudio,3)+s02a_02+area+s02a_02:aestudio+area:aestudio+exp(aestudio)+I(aestudio^4),data=bd3)
summary(model5)
ad.test(residuals(model5))

#trabajando sobre los valores atípicos desde R
library(MASS)
modela<-rlm(ylab~s02a_02+s02a_03+area,data=bd2)
modelb<-lm(ylab~s02a_02+s02a_03+area,data=bd2)
summary(modela)
summary(modelb)
ad.test(residuals(model))
# Colinealidad (X1=f(X2)
library(car)
vif(model3)
sqrt(vif(model3))>2 ##Variance Inflation Factors
# Verificar si la varianza es constante (homocedástico) o no (heterocedástico)
library(lmtest)
bptest(model3) # H0: Homocedsticidad https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test

#corrigiendo 
library(rms)
model1 = ols(ylab~s02a_02+s02a_03+area,data=bd3,x=T,y=T)
bptest(model1)
aux<-robcov(model1)
aux
# H0: Homocedasticidad, implica que los EE de B no son los correctos
```


### Paso 6: Predicir a partir del modelo

```{r,eval=F}
test<-bd3
yest<-predict(model3,test)
plot(log(bd3$ylab),yest)
plot(bd3$ylab,exp(yest))
```

## Probit y Logit

Estrategia, llevar valores binarios a valores continuos. Mediante una función de enlace ($F(Y)$).

$$F(Y)=Y'=X \beta +\epsilon$$

Probit:

$$Y=\Phi (X \beta +\epsilon)$$
$$\phi^{-1}(Y)=X \beta +\epsilon$$
$$Y'=X \beta +\epsilon$$

El enlace $F(Y)=\Phi^{-1}(Y)$, es conocida como probit.


Logit:

$$logit(Y)=log(\frac{Y}{1-Y})=X\beta+\epsilon$$

$$Y=\frac{e^{X\beta+\epsilon}}{1+e^{X\beta+\epsilon}}$$

### En R:

```{r,eval=F}
library(dplyr)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-384\\data\\eh18.Rdata")
aux<-levels(eh18p$s04a_01a)
eh18p<-eh18p %>% mutate(diabetes=(s04a_01a==aux[1] | s04a_01b==aux[1]),corazon=(s04a_01a==aux[4] | s04a_01b==aux[4]),hiper=(s04a_01a==aux[10] | s04a_01b==aux[10]))
eh18p$diabetes<-(eh18p$diabetes==T); eh18p$diabetes[is.na(eh18p$diabetes)]<-F
eh18p$corazon<-(eh18p$corazon==T); eh18p$corazon[is.na(eh18p$corazon)]<-F
eh18p$hiper<-(eh18p$hiper==T); eh18p$hiper[is.na(eh18p$hiper)]<-F
eh18p$cronicas<-(eh18p$diabetes+eh18p$corazon+eh18p$hiper)
#modelo para las enfermedades crónicas
eh18p$cronicas<-(eh18p$cronicas!=0)
#probit logit
logit<-glm(cronicas~s02a_02+s02a_03,data=eh18p,family = binomial(link="logit"))
probit<-glm(cronicas~s02a_02+s02a_03,data=eh18p,family = binomial(link="probit"))
lineal<-lm(cronicas~s02a_02+s02a_03,data=eh18p)
#resumen
summary(logit)
summary(probit)
summary(lineal)
#score probabilidades
lres<-predict(logit,eh18p,type="response")
pres<-predict(probit,eh18p,type="response")
plot(density(lres))
points(density(pres),type = "l",col="red")
#efectos marginales
library(mfx)
probitmfx(cronicas~s02a_02+s02a_03,data=eh18p)
logitmfx(cronicas~s02a_02+s02a_03,data=eh18p)
#ajuste
library(DescTools)
PseudoR2(logit)
PseudoR2(probit)
summary(lineal)
#comparando
library(memisc)
mtable(logit,probit,lineal)
```

```{r,eval=F}
summary(glm(cronicas~s02a_02+s02a_03,data=eh18p))
summary(lm(cronicas~s02a_02+s02a_03,data=eh18p))
```
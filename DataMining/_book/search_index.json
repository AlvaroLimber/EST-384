[
["index.html", "Minería de datos con R EST-384 Prefacio Audiencia Estructura del libro Software y acuerdos Datos Agradecimiento", " Minería de datos con R EST-384 Alvaro Chirino Gutierrez 2020-05-28 Prefacio Este documento de Alvaro Chirino esta bajo la licencia de Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Audiencia El libro fue diseñado originalmente para los estudiantes de la materia de Programación Estadística II, una materia optativa del pregrado de la carrera de Estadística de la Universidad Mayor de San Andrés. Este documento representa un primer acercamiento a los estudiantes de estadistica al software R y al mundo de la minería de datos. Estructura del libro El libro inluye 5 capitulos, estos son: Introducción a R Preparación de los datos Modelado en Minería de datos Minería de Texto Machine Learning Software y acuerdos sessionInfo() ## R version 4.0.0 (2020-04-24) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 18363) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Spanish_Bolivia.1252 ## [2] LC_CTYPE=Spanish_Bolivia.1252 ## [3] LC_MONETARY=Spanish_Bolivia.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=Spanish_Bolivia.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods ## [7] base ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.0 magrittr_1.5 bookdown_0.18 ## [4] htmltools_0.4.0 tools_4.0.0 rstudioapi_0.11 ## [7] yaml_2.2.1 Rcpp_1.0.4.6 stringi_1.4.6 ## [10] rmarkdown_2.1 knitr_1.28 stringr_1.4.0 ## [13] xfun_0.13 digest_0.6.25 packrat_0.5.0 ## [16] rlang_0.4.5 evaluate_0.14 Datos Agradecimiento Peeta… "],
["acerca-del-autor.html", "Acerca del autor Bibliografía", " Acerca del autor Bibliografía Torgo, L. (2016). Data mining with R: Learning with case studies, second edition. Hernandez, J. (2004). Introducción a la Minería de Datos Step, I., &amp; Blueprint, S. (2017). MACHINE LEARNING Intuitive Step by Step. "],
["minería-de-datos.html", "1 Minería de Datos 1.1 Motivación para la Mineria de datos 1.2 ¿Qué es la minería de datos? 1.3 Datos y conocimiento 1.4 Requerimientos 1.5 knowledge discovery in databases (KDD)", " 1 Minería de Datos 1.1 Motivación para la Mineria de datos Los métodos de recoleccion de datos han evolucionado muy rápidamente. Las bases de datos han crecido exponencialmente Estos datos contienen información útil para las empresas, paises, etc.. El tamaño hace que la inspección manual sea casi imposible Se requieren métodos de análisis de datos automáticos para optimizar el uso de estos enormes conjuntos de datos 1.2 ¿Qué es la minería de datos? Es el análisis de conjuntos de datos (a menudo grandes) para encontrar relaciones insospechadas (conocimiento) y resumir los datos de formas novedosas que sean comprensibles y útiles para el propietario/usuario de los datos. Principles of Data Mining (Hand et.al. 2001) 1.3 Datos y conocimiento 1.3.1 Datos: se refieren a instancias únicas y primitivas (single objetos, personas, eventos, puntos en el tiempo, etc.) describir propiedades individuales a menudo son fáciles de recolectar u obtener (por ejemplo, cajeros de escáner, internet, etc.) no nos permiten hacer predicciones o pronósticos 1.3.2 Conocimiento: se refiere a clases de instancias (conjuntos de …) describe patrones generales, estructuras, leyes, consta de la menor cantidad de declaraciones posibles a menudo es difícil y lleva mucho tiempo encontrar u obtener nos permite hacer predicciones y pronósticos 1.4 Requerimientos Disponibilidad para aprender Mucha paciencia Interactúa con otras áreas Preprocesamiento de datos Creatividad Rigor, prueba y error 1.5 knowledge discovery in databases (KDD) "],
["introR.html", "2 Introduccion a R 2.1 Tipos de estructuras 2.2 Loops y condiciones 2.3 Funciones 2.4 Importacion de datos 2.5 Dataframe y exploración 2.6 Estadística descriptiva 2.7 Muestreo e inferencia 2.8 Gráficos de origen 2.9 ggplot 2.10 R Markdown 2.11 Shiny 2.12 Ejercicios Propuestos", " 2 Introduccion a R 2.1 Tipos de estructuras 2.2 Loops y condiciones 2.3 Funciones 2.4 Importacion de datos 2.5 Dataframe y exploración 2.6 Estadística descriptiva 2.7 Muestreo e inferencia 2.8 Gráficos de origen 2.9 ggplot 2.10 R Markdown Este capitulo fue extraido en su mayoria de Xie, Allaire, and Grolemund (2018). “R Markdown” se introdujo por primera vez en el paquete knitr a principios de 2012. La idea era incrustar fragmentos de código (de R u otros) en los documentos de Markdown. De hecho, knitr soportó varios lenguajes de autoría desde el principio además de Markdown, incluidos LaTeX, HTML, AsciiDoc, reStructuredText y Textile. Markdown se ha convertido en el formato de documento más popular. La simplicidad de Markdown se destaca claramente entre estos formatos de documentos. 2.10.1 Instalación install.packages(&#39;rmarkdown&#39;) # Si se prefiere la versión en desarrollo if (!requireNamespace(&quot;devtools&quot;)) install.packages(&#39;devtools&#39;) devtools::install_github(&#39;rstudio/rmarkdown&#39;) Si el objetivo es usar Markdown para generar documentos PDF se necesita instalar Latex. Existen cheatsheets utiles para usar markdown, como: cheatsheets 2.10.2 YAML Header Al inicio del archivo y entre las lineas — --- title: Mi documento author: Juan Perez date: Marzo 22, 20220 output: html_document --- 2.10.3 Sintaxis básica Enfasis sobre el texto, *italic* **bold** _italic_ __bold__ Secciones, # Header 1 ## Header 2 ### Header 3 Items (viñetas) no ordenadas y ordenadas, * Item 1 * Item 2 + Item 2a + Item 2b 1. Item 1 2. Item 2 3. Item 3 + Item 3a + Item 3b Palabras clave con referencias web, [linked phrase](http://example.com) Imagenes simples o con titulo, ![](http://example.com/logo.png) ![optional caption text](figures/img.png) Blockquotes It’s always better to give than to receive. A friend once said: &gt; It&#39;s always better to give than to receive. Ecuaciones en linea y en parrafo, En linea \\(\\sum_i{x^2}\\) o en parrafo: \\[\\sum_i{x^2}\\] $equation$ $$ equation $$ 2.10.4 Tipos de documentos beamer_presentation github_document html_document ioslides_presentation latex_document md_document odt_document pdf_document powerpoint_presentation rtf_document slidy_presentation word_document 2.10.5 Chunks 2.11 Shiny 2.12 Ejercicios Propuestos "],
["references.html", "References", " References "],
["preparación-de-los-datos.html", "3 Preparación de los datos 3.1 Recopilación 3.2 Data Warehouse 3.3 Data Warehouse in R 3.4 Importación 3.5 Recopilación 3.6 Limpieza 3.7 Ejercicio (reshape) 3.8 Limpieza (fechas) 3.9 Limpieza (String) 3.10 Transfomración 3.11 Imputación de variables 3.12 La falta de información es información 3.13 Aproximación formal 3.14 MCAR, MAR, MNAR 3.15 Alternativas para trabajar con los Missings (Ad-hoc) 3.16 Imputación Multiple 3.17 Patrones en datos multivariados 3.18 Influx and outflux 3.19 Imputación de datos monótonos 3.20 Multivariate Imputation by Chained Equations (mice) 3.21 En R", " 3 Preparación de los datos 3.1 Recopilación Instituto de Estadística UDAPE, ASFI Ministerio Salud (SNIS), Ministerio de educación (SIE) APIs, Twitter, Facebook, etc. Kaggle Banco Mundial, UNICEF, FAO, BID (Open Data) 3.2 Data Warehouse 3.3 Data Warehouse in R 3.4 Importación library(foreign) library(readr) apropos(&quot;read&quot;) ## [1] &quot;.rs.api.readPreference&quot; ## [2] &quot;.rs.connectionReadDSN&quot; ## [3] &quot;.rs.connectionReadInstallers&quot; ## [4] &quot;.rs.connectionReadOdbc&quot; ## [5] &quot;.rs.connectionReadOdbcEntry&quot; ## [6] &quot;.rs.connectionReadPackageInstallers&quot; ## [7] &quot;.rs.connectionReadPackages&quot; ## [8] &quot;.rs.connectionReadSnippets&quot; ## [9] &quot;.rs.connectionReadWindowsRegistry&quot; ## [10] &quot;.rs.isREADME&quot; ## [11] &quot;.rs.odbcBundleReadIni&quot; ## [12] &quot;.rs.onAvailablePackagesReady&quot; ## [13] &quot;.rs.readAliases&quot; ## [14] &quot;.rs.readDataCapture&quot; ## [15] &quot;.rs.readFile&quot; ## [16] &quot;.rs.readIniFile&quot; ## [17] &quot;.rs.readLines&quot; ## [18] &quot;.rs.readPackageDescription&quot; ## [19] &quot;.rs.readRnbCache&quot; ## [20] &quot;.rs.readShinytestResultRds&quot; ## [21] &quot;.rs.readSourceDocument&quot; ## [22] &quot;.rs.readUiPref&quot; ## [23] &quot;.rs.rnb.readConsoleData&quot; ## [24] &quot;read.arff&quot; ## [25] &quot;read.csv&quot; ## [26] &quot;read.csv2&quot; ## [27] &quot;read.dbf&quot; ## [28] &quot;read.dcf&quot; ## [29] &quot;read.delim&quot; ## [30] &quot;read.delim2&quot; ## [31] &quot;read.DIF&quot; ## [32] &quot;read.dta&quot; ## [33] &quot;read.epiinfo&quot; ## [34] &quot;read.fortran&quot; ## [35] &quot;read.ftable&quot; ## [36] &quot;read.fwf&quot; ## [37] &quot;read.mtp&quot; ## [38] &quot;read.octave&quot; ## [39] &quot;read.S&quot; ## [40] &quot;read.socket&quot; ## [41] &quot;read.spss&quot; ## [42] &quot;read.ssd&quot; ## [43] &quot;read.systat&quot; ## [44] &quot;read.table&quot; ## [45] &quot;read.xport&quot; ## [46] &quot;read_csv&quot; ## [47] &quot;read_csv_chunked&quot; ## [48] &quot;read_csv2&quot; ## [49] &quot;read_csv2_chunked&quot; ## [50] &quot;read_delim&quot; ## [51] &quot;read_delim_chunked&quot; ## [52] &quot;read_file&quot; ## [53] &quot;read_file_raw&quot; ## [54] &quot;read_fwf&quot; ## [55] &quot;read_lines&quot; ## [56] &quot;read_lines_chunked&quot; ## [57] &quot;read_lines_raw&quot; ## [58] &quot;read_lines_raw_chunked&quot; ## [59] &quot;read_log&quot; ## [60] &quot;read_rds&quot; ## [61] &quot;read_table&quot; ## [62] &quot;read_table2&quot; ## [63] &quot;read_tsv&quot; ## [64] &quot;read_tsv_chunked&quot; ## [65] &quot;readBin&quot; ## [66] &quot;readChar&quot; ## [67] &quot;readCitationFile&quot; ## [68] &quot;readClipboard&quot; ## [69] &quot;readline&quot; ## [70] &quot;readLines&quot; ## [71] &quot;readr_example&quot; ## [72] &quot;readRDS&quot; ## [73] &quot;readRegistry&quot; ## [74] &quot;readRenviron&quot; ## [75] &quot;Sys.readlink&quot; 3.5 Recopilación read.table(&quot;clipboard&quot;,header = T) library(readxl) library(dplyr) library(DBI) library(RMySQL) library(gtrendsR) # API 3.6 Limpieza std&lt;-data.frame(name=c(&quot;ana&quot;,&quot;juan&quot;,&quot;carla&quot;),math=c(86,43,80),stat=c(90,75,82)) std ## name math stat ## 1 ana 86 90 ## 2 juan 43 75 ## 3 carla 80 82 library(tidyr) bd&lt;-gather(std,materia,nota,math:stat) bd ## name materia nota ## 1 ana math 86 ## 2 juan math 43 ## 3 carla math 80 ## 4 ana stat 90 ## 5 juan stat 75 ## 6 carla stat 82 3.7 Ejercicio (reshape) http://www.udape.gob.bo/portales_html/dossierweb2019/htms/CAP07/C070311.xls 3.8 Limpieza (fechas) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union ymd(&quot;20151021&quot;) ## [1] &quot;2015-10-21&quot; ymd(&quot;2015/11/30&quot;) ## [1] &quot;2015-11-30&quot; myd(&quot;11.2012.3&quot;) ## [1] &quot;2012-11-03&quot; dmy_hms(&quot;2/12/2013 14:05:01&quot;) ## [1] &quot;2013-12-02 14:05:01 UTC&quot; mdy(&quot;120112&quot;) ## [1] &quot;2012-12-01&quot; 3.9 Limpieza (String) toupper(&quot;hola&quot;) ## [1] &quot;HOLA&quot; abc&lt;-letters[1:10] toupper(abc) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; tolower(&quot;HOLA&quot;) ## [1] &quot;hola&quot; tolower(&quot;Juan&quot;) ## [1] &quot;juan&quot; substr(&quot;hola como estan&quot;,1,3) ## [1] &quot;hol&quot; substr(&quot;hola como estan&quot;,3,7) ## [1] &quot;la co&quot; nchar(&quot;hola&quot;) ## [1] 4 gsub(&quot;a&quot;,&quot;x&quot;,&quot;hola como estas&quot;) ## [1] &quot;holx como estxs&quot; grepl(&quot;a&quot;,c(&quot;hola&quot;,&quot;como&quot;)) ## [1] TRUE FALSE grepl(&quot;o&quot;,c(&quot;hola&quot;,&quot;como&quot;)) ## [1] TRUE TRUE library(stringi) 3.10 Transfomración Estandarizar variables Función logarítmo Creación de variables Recodificar variables 3.11 Imputación de variables We should be suspicious of any dataset (large or small) which appears perfect. — David J. Hand 3.12 La falta de información es información MCAR missing completely at random MAR missing at random MNAR missing not at random 3.13 Aproximación formal Sea \\(Y\\) una matriz de datos con \\(n\\) observaciones y \\(p\\) variables. Sea \\(R\\) una matriz de respuesta binaria, tal que si \\(y_{ij}\\) es observada, entonces \\(r_{ij}=1\\). Los valores observados son colectados en \\(Y_{obs}\\), las observaciones perdidas en \\(Y_{mis}\\). Así, \\(Y=(Y_{obs},Y_{mis})\\). La distribución de \\(R\\) depende de \\(Y=(Y_{obs},Y_{mis})\\). Sea \\(\\psi\\) que contiene los parametros del modelos de los datos perdidos, asi la expresion del modelo de los datos perdidos es \\(\\Pr(R|Y_\\mathrm{obs},Y_\\mathrm{mis},\\psi)\\) 3.14 MCAR, MAR, MNAR MCAR (missing completely at random ) \\[ \\Pr(R=0|{\\mbox{$Y_\\mathrm{obs}$}},{\\mbox{$Y_\\mathrm{mis}$}},\\psi) = \\Pr(R=0|\\psi) \\] MAR (missing at random ) \\[ \\Pr(R=0|{\\mbox{$Y_\\mathrm{obs}$}},{\\mbox{$Y_\\mathrm{mis}$}},\\psi) = \\Pr(R=0|{\\mbox{$Y_\\mathrm{obs}$}},\\psi) \\] MNAR (missing not at random ) \\[ \\Pr(R=0|{\\mbox{$Y_\\mathrm{obs}$}},{\\mbox{$Y_\\mathrm{mis}$}},\\psi) \\] 3.15 Alternativas para trabajar con los Missings (Ad-hoc) Listwise deletion Pairwise deletion Mean imputation Regression imputation Stochastic regression imputation Last observation carried forward (LOCF) and baseline observation carried forward (BOCF) Indicator method 3.16 Imputación Multiple 3.17 Patrones en datos multivariados 3.18 Influx and outflux \\[ I_j = \\frac{\\sum_j^p\\sum_k^p\\sum_i^n (1-r_{ij})r_{ik}}{\\sum_k^p\\sum_i^n r_{ik}} \\] La variable con mayor influx está mejor conectada a los datos observados y, por lo tanto, podría ser más fácil de imputar. \\[ O_j = \\frac{\\sum_j^p\\sum_k^p\\sum_i^n r_{ij}(1-r_{ik})}{\\sum_k^p\\sum_i^n 1-r_{ij}} \\] La variable con mayor outflux está mejor conectada a los datos faltantes, por lo tanto, es potencialmente más útil para imputar otras variables. 3.19 Imputación de datos monótonos 3.20 Multivariate Imputation by Chained Equations (mice) (Imputación multivariante por ecuaciones encadenadas) 3.21 En R "],
["preparación-de-los-datos-1.html", "4 Preparación de los datos 4.1 Recopilación de datos 4.2 Importación y exploración 4.3 Limpieza y transformación 4.4 Métodos de imputación", " 4 Preparación de los datos 4.1 Recopilación de datos 4.2 Importación y exploración 4.3 Limpieza y transformación 4.4 Métodos de imputación "],
["modelado-en-minería-de-datos.html", "5 Modelado en Minería de datos 5.1 Explorando los datos 5.2 Componentes Principales 5.3 Análisis de correspondencia", " 5 Modelado en Minería de datos 5.1 Explorando los datos Existen dos aproximaciones para empezar a explorar la información existente en una base de datos: Resumen de los datos Visualización de los datos 5.1.1 Resumen de los datos Dado el tamaño de las bases de datos resulta imposible o muy dificil conocer todas sus propiedad, el resumen de los datos intenta brindar propiedades claves de los datos, estas propiedades podrian ser: Cual es el valor mas comun Cuan variable o dispersa esta la informacion Existen valores extraños o inesparedaps en la base de datos Los datos siguen alguna distribucion A continuación se emplea la encuesta a hogares 2018 para ir respondiendo estas preguntas. En cuanto a los valores mas comunes, la media y la mediana de los datos son suficientes para las variables cuantitativas, mientra que para variables cualitativas, las categorias mas frecuentes son una buena opción. load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/master/data/eh18.Rdata&quot;)) # media de edad mean(eh18p$s02a_03) ## [1] 29.59059 #mediana de edad median(eh18p$s02a_03) ## [1] 26 # para las categorias mas frecuentes library(DMwR2) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:lubridate&#39;: ## ## intersect, setdiff, union ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union #para el sexo centralValue(eh18p$s02a_02) ## [1] &quot;2.Mujer&quot; #para el departamento centralValue(eh18p$depto) ## [1] &quot;La Paz&quot; A veces es mejor ver los resultados por grupos, por ejemplo, podemos verlo por departamento y area. eh18p %&gt;% group_by(depto,area) %&gt;% summarise(mean(s02a_03),median(s02a_03),centralValue(s02a_02),n()) ## # A tibble: 18 x 6 ## # Groups: depto [9] ## depto area `mean(s02a_03)` `median(s02a_03~ `centralValue(s~ ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Chuq~ Urba~ 28.7 24 2.Mujer ## 2 Chuq~ Rural 31.0 27 2.Mujer ## 3 La P~ Urba~ 30.4 27 2.Mujer ## 4 La P~ Rural 34.3 31 2.Mujer ## 5 Coch~ Urba~ 30.4 27 2.Mujer ## 6 Coch~ Rural 31.1 27.5 1.Hombre ## 7 Oruro Urba~ 28.7 26 2.Mujer ## 8 Oruro Rural 36.4 34 2.Mujer ## 9 Poto~ Urba~ 26.1 23 2.Mujer ## 10 Poto~ Rural 35.6 34.5 2.Mujer ## 11 Tari~ Urba~ 29.4 27 2.Mujer ## 12 Tari~ Rural 29.7 27 2.Mujer ## 13 Sant~ Urba~ 27.8 25 2.Mujer ## 14 Sant~ Rural 29.9 26 1.Hombre ## 15 Beni Urba~ 26.8 22 2.Mujer ## 16 Beni Rural 26.0 19 1.Hombre ## 17 Pando Urba~ 25.5 23 1.Hombre ## 18 Pando Rural 22.6 18 1.Hombre ## # ... with 1 more variable: `n()` &lt;int&gt; La función n() realiza un proceso de conteo. De forma similar podemos hacer para las medidas de variabilidad, las mas comunes la desviacion estandar, el rango, el rango intercuartil y los cuantiles. Usando la eh18 para la edad y el ingreso laboral. ##EDAD # Desviacion estandar sd(eh18p$s02a_03) ## [1] 20.97181 # Rango range(eh18p$s02a_03) ## [1] 0 98 # Rango intercuartil IQR(eh18p$s02a_03) ## [1] 32 # Quantiles quantile(eh18p$s02a_03) ## 0% 25% 50% 75% 100% ## 0 12 26 44 98 quantile(eh18p$s02a_03,c(0.10,0.90)) ## 10% 90% ## 5 61 ##INGRESO LABORAL # Desviacion estandar sd(eh18p$ylab,na.rm = T) ## [1] 2242.593 # Rango range(eh18p$ylab,na.rm = T) ## [1] 4.166667 36196.667969 # Rango intercuartil IQR(eh18p$ylab,na.rm = T) ## [1] 2397 # Quantiles quantile(eh18p$ylab,na.rm = T) ## 0% 25% 50% 75% 100% ## 4.166667 1500.000000 2554.699951 3897.000000 36196.667969 quantile(eh18p$s02a_03,probs=c(0.10,0.90),na.rm = T) ## 10% 90% ## 5 61 ##por departamento y area tapply(eh18p$ylab,list(eh18p$depto,eh18p$area),sd,na.rm=T)#opcion1 ## Urbana Rural ## Chuquisaca 2586.058 1735.306 ## La Paz 2154.421 1703.794 ## Cochabamba 2313.400 1654.140 ## Oruro 2425.280 1622.623 ## Potosí 2308.412 1534.399 ## Tarija 2287.537 2142.638 ## Santa Cruz 2156.938 2134.006 ## Beni 2419.952 1809.108 ## Pando 1778.112 2050.242 tapply(eh18p$ylab,list(eh18p$depto,eh18p$area),quantile,na.rm=T)#con problemas ## Urbana Rural ## Chuquisaca Numeric,5 Numeric,5 ## La Paz Numeric,5 Numeric,5 ## Cochabamba Numeric,5 Numeric,5 ## Oruro Numeric,5 Numeric,5 ## Potosí Numeric,5 Numeric,5 ## Tarija Numeric,5 Numeric,5 ## Santa Cruz Numeric,5 Numeric,5 ## Beni Numeric,5 Numeric,5 ## Pando Numeric,5 Numeric,5 aggregate(eh18p$ylab,list(depto=eh18p$depto,area=eh18p$area),quantile,na.rm=T) ## depto area x.0% x.25% x.50% ## 1 Chuquisaca Urbana 39.583336 1317.083344 2598.000000 ## 2 La Paz Urbana 6.666667 1732.000000 2650.000000 ## 3 Cochabamba Urbana 80.000000 1850.833374 2700.000000 ## 4 Oruro Urbana 15.000000 1608.679932 2598.000000 ## 5 Potosí Urbana 160.000000 1724.750000 3064.550049 ## 6 Tarija Urbana 86.599998 1794.533325 2814.500000 ## 7 Santa Cruz Urbana 80.000000 2121.699951 2976.875000 ## 8 Beni Urbana 50.000000 1729.834961 2500.000000 ## 9 Pando Urbana 250.000000 2475.000000 3291.666748 ## 10 Chuquisaca Rural 36.666668 519.599976 1012.489990 ## 11 La Paz Rural 12.500000 300.000000 825.000000 ## 12 Cochabamba Rural 23.333334 523.649994 1590.000061 ## 13 Oruro Rural 19.166668 286.458336 653.916687 ## 14 Potosí Rural 25.833334 225.000000 516.250000 ## 15 Tarija Rural 4.166667 995.883316 1967.666687 ## 16 Santa Cruz Rural 66.666672 1230.000000 2262.250000 ## 17 Beni Rural 100.000000 705.000000 1800.000000 ## 18 Pando Rural 80.000000 1207.500000 2167.500000 ## x.75% x.100% ## 1 4369.449707 16123.333008 ## 2 3897.000000 23437.484375 ## 3 4000.000000 36196.667969 ## 4 4330.000000 16166.666992 ## 5 4500.000000 14072.500000 ## 6 4330.000000 21833.000000 ## 7 4156.799805 35668.664062 ## 8 4105.924927 22700.000000 ## 9 4538.041748 11367.666016 ## 10 2078.399902 10120.000000 ## 11 2249.166748 15433.333008 ## 12 2598.000000 10825.000000 ## 13 2051.324982 10175.500000 ## 14 1435.208374 7333.333496 ## 15 3366.749939 16730.000000 ## 16 3167.366516 22465.667969 ## 17 3500.000000 7577.500000 ## 18 3449.133362 19750.000000 Finalmente, para explorar a fondo las variables la funcion describe es bastante útil, tambien, el comando summary. #analizando las 5 primeras variables de la base de datos library(Hmisc) ## Loading required package: lattice ## Loading required package: survival ## Loading required package: Formula ## Loading required package: ggplot2 ## Keep up to date with changes at ## https://www.tidyverse.org/blog/ ## ## Attaching package: &#39;Hmisc&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## src, summarize ## The following objects are masked from &#39;package:base&#39;: ## ## format.pval, units describe(eh18p[,1:5]) ## eh18p[, 1:5] ## ## 5 Variables 37517 Observations ## ------------------------------------------------------------------ ## folio ## n missing distinct ## 37517 0 11195 ## ## lowest : 111-00419704629-A-0011 111-00419704629-A-0021 111-00419704629-A-0041 111-00419704629-A-0051 111-00419704629-A-0071 ## highest: 953-11761951198-D-0081 953-11761951198-D-0091 953-11761951198-D-0101 953-11761951198-D-0111 953-11761951198-D-0121 ## ------------------------------------------------------------------ ## nro ## n missing distinct Info Mean Gmd .05 ## 37517 0 13 0.948 2.639 1.712 1 ## .10 .25 .50 .75 .90 .95 ## 1 1 2 4 5 6 ## ## lowest : 1 2 3 4 5, highest: 9 10 11 12 13 ## ## Value 1 2 3 4 5 6 7 8 9 ## Frequency 11195 9399 7215 4892 2654 1230 536 231 110 ## Proportion 0.298 0.251 0.192 0.130 0.071 0.033 0.014 0.006 0.003 ## ## Value 10 11 12 13 ## Frequency 39 13 2 1 ## Proportion 0.001 0.000 0.000 0.000 ## ------------------------------------------------------------------ ## depto ## n missing distinct ## 37517 0 9 ## ## lowest : Chuquisaca La Paz Cochabamba Oruro Potosí ## highest: Potosí Tarija Santa Cruz Beni Pando ## ## Value Chuquisaca La Paz Cochabamba Oruro Potosí ## Frequency 2117 9970 7578 2188 1855 ## Proportion 0.056 0.266 0.202 0.058 0.049 ## ## Value Tarija Santa Cruz Beni Pando ## Frequency 3088 6561 2516 1644 ## Proportion 0.082 0.175 0.067 0.044 ## ------------------------------------------------------------------ ## area ## n missing distinct ## 37517 0 2 ## ## Value Urbana Rural ## Frequency 29212 8305 ## Proportion 0.779 0.221 ## ------------------------------------------------------------------ ## s02a_02 ## n missing distinct ## 37517 0 2 ## ## Value 1.Hombre 2.Mujer ## Frequency 18419 19098 ## Proportion 0.491 0.509 ## ------------------------------------------------------------------ summary(eh18p$ylab) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 4.17 1500.00 2554.70 2959.39 3897.00 36196.67 22852 by(eh18p[,c(&quot;ylab&quot;,&quot;p0&quot;,&quot;s02a_03&quot;)],eh18p$area,summary) ## eh18p$area: Urbana ## ylab p0 s02a_03 ## Min. : 6.67 No Pobre:21225 Min. : 0.00 ## 1st Qu.: 1839.08 Pobre : 7971 1st Qu.:13.00 ## Median : 2788.52 NA&#39;s : 16 Median :26.00 ## Mean : 3238.21 Mean :29.17 ## 3rd Qu.: 4082.50 3rd Qu.:43.00 ## Max. :36196.67 Max. :98.00 ## NA&#39;s :17573 ## ------------------------------------------------- ## eh18p$area: Rural ## ylab p0 s02a_03 ## Min. : 4.167 No Pobre:4049 Min. : 0.00 ## 1st Qu.: 476.392 Pobre :4254 1st Qu.:11.00 ## Median : 1300.000 NA&#39;s : 2 Median :27.00 ## Mean : 1886.938 Mean :31.06 ## 3rd Qu.: 2657.667 3rd Qu.:49.00 ## Max. :22465.668 Max. :98.00 ## NA&#39;s :5279 5.1.2 Visualización La visualizacion es una herramienta importante para explorar y entender la base de datos. Los seres humanos son excelentes para capturar patrones visuales, y la visualización de datos intenta capitalizar en estas habilidades. Es util diferenciar las visualizaciones por: Una sola varibles Dos variables Multiples variables Los aspetor vinculados al uso de graficos de origen de R y la libreria ggplot pueden verse en el texto guia de EST-183 “BigData”. A continuación se introducen de forma directa funciones en R orientadas a la visualización univariante, bivariante y multivariante. Usando al EH-2018, para variables cualitativas. #Graficos de origen de R barplot(table(eh18p$s03a_01a),main=&quot;Dónde vivia hace 5 años?&quot;) #GGPLOT library(ggplot2) ggplot(eh18p,aes(x=s03a_01a))+geom_bar()+ggtitle(&quot;Dónde vivia hace 5 años?&quot;) Para variables del tipo cuantitativas par(mfrow=c(1,2)) boxplot(eh18p$ylab) hist(eh18p$ylab) dev.off() ## null device ## 1 ggplot(eh18p,aes(ylab))+geom_boxplot() ## Warning: Removed 22852 rows containing non-finite values ## (stat_boxplot). ggplot(eh18p,aes(ylab))+geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with ## `binwidth`. ## Warning: Removed 22852 rows containing non-finite values ## (stat_bin). Si ahora queremos comparar usar ambas variables cuanti y cuali boxplot(eh18p$ylab~eh18p$s03a_01a) ggplot(eh18p,aes(x=s03a_01a,y=ylab))+geom_boxplot() ## Warning: Removed 22852 rows containing non-finite values ## (stat_boxplot). ggplot(eh18p,aes(x=s03a_01a,y=ylab))+geom_violin() ## Warning: Removed 22852 rows containing non-finite values ## (stat_ydensity). Usando ambas variables cuantitativas plot(eh18p$tothrs,eh18p$ylab) plot(eh18p[,c(&quot;ylab&quot;,&quot;tothrs&quot;,&quot;aestudio&quot;)]) #pairs(eh18p[,c(&quot;ylab&quot;,&quot;tothrs&quot;,&quot;aestudio&quot;)]) similar al anterior library(GGally) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ## ## Attaching package: &#39;GGally&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## nasa ggpairs(eh18p,columns = c(&quot;ylab&quot;,&quot;tothrs&quot;,&quot;aestudio&quot;)) library(ggridges) # basic example ggplot(eh18p[eh18p$s02a_03&gt;=15,], aes(x = ylab, y = s02a_02, fill = s02a_02)) + geom_density_ridges() + theme_ridges() + theme(legend.position = &quot;none&quot;)+ ggtitle(&quot;Ingreso laboral por sexo, personas de 15 años o más&quot;) ## Picking joint bandwidth of 257 Ahora si combinamos variables cuanti y cuali con ggpairs. ggpairs(eh18p,columns = c(&quot;ylab&quot;,&quot;tothrs&quot;,&quot;s03a_01a&quot;,&quot;area&quot;)) ## plot: [1,1] [=&gt;----------------------------------] 6% est: 0s ## Warning: Removed 22852 rows containing non-finite values ## (stat_density). ## plot: [1,2] [===&gt;--------------------------------] 12% est: 1s ## Warning in (function (data, mapping, alignPercent = 0.6, method = ## &quot;pearson&quot;, : Removed 22855 rows containing missing values ## plot: [1,3] [======&gt;-----------------------------] 19% est: 1s ## Warning: Removed 22852 rows containing non-finite values ## (stat_boxplot). ## plot: [1,4] [========&gt;---------------------------] 25% est: 1s ## Warning: Removed 22852 rows containing non-finite values ## (stat_boxplot). ## plot: [2,1] [==========&gt;-------------------------] 31% est: 1s ## Warning: Removed 22855 rows containing missing values ## (geom_point). ## plot: [2,2] [=============&gt;----------------------] 38% est: 2s ## Warning: Removed 20551 rows containing non-finite values ## (stat_density). ## plot: [2,3] [===============&gt;--------------------] 44% est: 1s ## Warning: Removed 20551 rows containing non-finite values ## (stat_boxplot). ## plot: [2,4] [=================&gt;------------------] 50% est: 1s ## Warning: Removed 20551 rows containing non-finite values ## (stat_boxplot). ## plot: [3,1] [===================&gt;----------------] 56% est: 1s `stat_bin()` using `bins = 30`. Pick better value with ## `binwidth`. ## Warning: Removed 22852 rows containing non-finite values ## (stat_bin). ## plot: [3,2] [=====================&gt;--------------] 62% est: 1s `stat_bin()` using `bins = 30`. Pick better value with ## `binwidth`. ## Warning: Removed 20551 rows containing non-finite values ## (stat_bin). ## plot: [3,3] [========================&gt;-----------] 69% est: 1s plot: [3,4] [==========================&gt;---------] 75% est: 1s plot: [4,1] [============================&gt;-------] 81% est: 1s `stat_bin()` using `bins = 30`. Pick better value with ## `binwidth`. ## Warning: Removed 22852 rows containing non-finite values ## (stat_bin). ## plot: [4,2] [===============================&gt;----] 88% est: 0s `stat_bin()` using `bins = 30`. Pick better value with ## `binwidth`. ## Warning: Removed 20551 rows containing non-finite values ## (stat_bin). ## plot: [4,3] [=================================&gt;--] 94% est: 0s ## plot: [4,4] [====================================]100% est: 0s Alternativas Multivariantes, #trabajando a partir de una muestra de 100 individuos s&lt;-sample(1:dim(eh18p)[1],100) i&lt;-match(c(&quot;s02a_03&quot;,&quot;aestudio&quot;,&quot;ylab&quot;,&quot;tothrs&quot;),names(eh18p)) ggparcoord(eh18p[s,],columns = i,groupColumn = &quot;area&quot;,boxplot=T) library(&quot;TeachingDemos&quot;) ## ## Attaching package: &#39;TeachingDemos&#39; ## The following objects are masked from &#39;package:Hmisc&#39;: ## ## cnvrt.coords, subplot faces(na.omit(eh18p[s,i])) 5.2 Componentes Principales El método de Análisis de Componentes Principales se ocupa de explicar la estructura de varianza y covarianza de un grupo de variables a través de unas pocas combinaciones lineales de este grupo de variables. En general sus objetivos son (1) la reducción de los datos y (2) la interpretación. Algebráicamente, los componentes principales son combinaciones lineales de \\(p\\) variables aleatorias \\(X_1\\), \\(X_2\\), , \\(X_p\\). Geométricamente, estas combinaciones lineales representan la selección de un nuevo sistema de coordenadas obtenido por rotación de del sistema original con \\(X_1\\), \\(X_2\\), , \\(X_p\\) como los ejes de coordenadas. Los nuevos ejes representan la dirección con la máxima variabilidad y provee una simple y más parsimoniosa descripción de la estructura de la covarianza. Los componentes principales dependen únicamente de la matriz de covarianza \\(\\Sigma\\) o la matriz de correlaciones \\(\\rho\\) (Matriz estandarizada de \\(\\Sigma\\)) de \\(X_1\\), \\(X_2\\), , \\(X_p\\). Su desarrollo no requiere de ningún supuesto de normalidad multivariada, sin embargo, componentes principales derivados de poblaciones normales multivariantes tienen un gran uso en la interpretación en términos de elipsoide de densidad constante. Sea la matriz \\(\\mathbf{X}\\) compuesta de \\(p\\) vectores aleatorios \\(\\mathbf{X}=[X_1, X_2, \\ldots, X_p ]\\) que tiene la matriz de covarianza \\(\\Sigma\\) con valores propios \\(\\lambda_1 \\geq \\lambda_2 \\geq \\ldots \\geq \\lambda_p \\geq 0\\). Considere la combinación lineal: \\[\\begin{equation} \\begin{array}{rrr} Y_1 = &amp; a_1^{&#39;} \\mathbf{X} = &amp; a_{11} X_1 + a_{12} X_2 + \\ldots a_{1p} X_p \\\\ Y_2 = &amp; a_2^{&#39;} \\mathbf{X} = &amp; a_{21} X_1 + a_{22} X_2 + \\ldots a_{2p} X_p\\\\ \\vdots = &amp; \\vdots &amp; \\vdots \\\\ Y_p = &amp; a_p^{&#39;} \\mathbf{X} = &amp; a_{p1} X_1 + a_{p2} X_2 + \\ldots a_{pp} X_p\\\\ \\end{array} \\label{cp1} \\end{equation}\\] Equivalente a: \\[\\begin{equation} \\mathbf{Y}= \\left[ \\begin{array}{c} Y_1\\\\ Y_2\\\\ \\vdots\\\\ Y_p\\\\ \\end{array} \\right] = \\left[ \\begin{array}{cccc} a_{11} &amp; a_{12} &amp; \\ldots &amp; a_{1p} \\\\ a_{21} &amp; a_{22} &amp; \\ldots &amp; a_{2p} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{21} &amp; a_{p2} &amp; \\ldots &amp; a_{pp} \\\\ \\end{array} \\right] \\left[ \\begin{array}{c} X_1\\\\ X_2\\\\ \\vdots\\\\ X_p\\\\ \\end{array} \\right] = \\mathbf{A X} \\label{cp2} \\end{equation}\\] La combinación lineal \\(\\mathbf{Y}=\\mathbf{AX}\\) tiene: \\[\\begin{equation} \\mu_y=E(\\mathbf{Y})=E(\\mathbf{AX})=A \\mu_x \\label{cp3} \\end{equation}\\] \\[\\begin{equation} \\Sigma_y=Cov(\\mathbf{Y})=Cov(\\mathbf{AX})=A \\Sigma A^{&#39;} \\label{cp4} \\end{equation}\\] En base a , se obtiene: \\[\\begin{equation} Var(Y_i)=a_i^{&#39;} \\Sigma a_i \\quad i=1, 2, \\ldots, p \\label{cp5} \\end{equation}\\] \\[\\begin{equation} Cov(Y_i,Y_k)=a_i^{&#39;} \\Sigma a_k \\quad i,k=1, 2, \\ldots, p \\label{cp6} \\end{equation}\\] Los componentes principales son combinaciones lineales incorrelacionadas, tal que es lo más grande posible. El primer componente principal es la combinación lineal con máxima varianza. Entonces se debe maximizar \\(Var(Y_1)=a_1^{&#39;} \\Sigma a_1\\). Es claro que \\(Var(Y_1)\\) puede ser incrementada multiplicando a \\(a_1\\) por alguna constante. Para eliminar esta indeterminación, es conveniente restringir los coeficientes del vector. Por lo tanto se define. \\[ \\begin{array}{rcl} \\text{Primer componente principal} &amp; = &amp; \\text{Combinacion lineal} \\quad a_1^{&#39;}X \\quad \\text{que maximiza} \\\\ &amp; &amp; Var(a_1^{&#39;}X) \\quad \\text{sujeto a} \\quad a_1^{&#39;} a_1=1\\\\ \\text{Segundo componente principal} &amp; = &amp; \\text{Combinacion lineal} \\quad a_2^{&#39;}X \\quad \\text{que maximiza} \\\\ &amp; &amp; Var(a_2^{&#39;}X) \\quad \\text{sujeto a} \\quad a_2^{&#39;} a_2=1 \\quad y \\\\ &amp; &amp; Cov(a_1^{&#39;}X,a_2^{&#39;}X)=0 \\end{array} \\] Para el \\(i-esimo\\) paso: \\[ \\begin{array}{rcl} i-esimo \\text{ componente principal} &amp; = &amp; \\text{Combinacion lineal} \\quad a_i^{&#39;}X \\quad \\text{que maximiza} \\\\ &amp; &amp; Var(a_i^{&#39;}X) \\quad \\text{sujeto a} \\quad a_i^{&#39;} a_i=1 \\quad y \\\\ &amp; &amp; Cov(a_i^{&#39;}X,a_k^{&#39;}X)=0 \\quad para \\quad k&lt;i \\end{array} \\] Los pasos sugeridos para iniciar el analisis de componentes principales son: Identificar las variables de interés dentro de la matriz de datos, si las variables tienen las mismas escalas se recomienda emplear la matriz de covarianza, si las escalas son diferentes, se recomienda trabajar con la matriz de correlaciones. Obtener los componentes principales, los eigen valores y la matriz de eigen vectores Eliminar las variables rebundantes, se sugiere identificar las variables del conjunto de datos correlacionadas con los últimos componentes Calcular nuevamente los componentes principales expluyendo las variables identificadas en el paso previo Elegir el número de componentes a retener (scree plot, tamaño de los eigen valores, etc) Analizar los resultados #1. Seleccione una base de datos de interés del repositorio load(url(&quot;https://github.com/AlvaroLimber/EST-384/blob/master/data/oct20.RData?raw=true&quot;)) #2. Seleccione las variables para el PCA (Según la motivación) vv&lt;-c(14:22,24,25) #2A TRANFORMAR vval&lt;-apply(computo[,vv],1,sum) aux&lt;-computo[,vv]/vval #2B LIMPIEZA #3. Calcule el PCA aux1&lt;-na.omit(aux) cp1&lt;-eigen(cov(aux1)) cp2&lt;-eigen(cor(aux1)) #4. Identifique el número de CPs que explican hasta el 90% de la varianza cumsum(cp1$values)/sum(cp1$values) ## [1] 0.6437488 0.8650934 0.9435882 0.9722772 0.9839750 0.9903314 ## [7] 0.9952079 0.9977119 0.9991579 1.0000000 1.0000000 cumsum(cp2$values)/sum(cp2$values) ## [1] 0.2060107 0.3791103 0.4915437 0.5920446 0.6774866 0.7601857 ## [7] 0.8319256 0.8991550 0.9562490 1.0000000 1.0000000 #5. Identifique las variables correlacionadas con la cantidad de #componentes fuera del 90% del paso anterior cp11cov&lt;-as.matrix(aux1)%*%cp1$vectors[,11] cp11cor&lt;-as.matrix(aux1)%*%cp2$vectors[,11] cor(cbind(aux1,cp11cov,cp11cor))[1:11,12:13] ## cp11cov cp11cor ## CC 0.53979440 -0.30842297 ## FPV -0.55376059 0.21633850 ## MTS 0.13333915 0.40515623 ## UCS -0.34677314 0.35428285 ## MAS - IPSP -0.21854796 -0.41971569 ## 21F -0.38433159 0.53263368 ## PDC -0.12174043 -0.01216537 ## MNR -0.21628303 0.41542663 ## PAN-BOL 0.11710134 0.09577694 ## Blancos -0.07666553 0.50453525 ## Nulos -0.11039942 0.18712933 cp11&lt;-eigen(cov(aux1[,-2])) cumsum(cp11$values)/sum(cp11$values) ## [1] 0.6443329 0.8658697 0.9444240 0.9730984 0.9847943 0.9911498 ## [7] 0.9960295 0.9984949 0.9999206 1.0000000 cp10cov&lt;-as.matrix(aux1[,-2])%*%cp11$vectors[,10] #6. Calcule nuevamente el componente principal eliminando las variables rebundantes #7. Determine la cantidad de componentes principales a retener cp1cov&lt;-as.matrix(aux1[,-2])%*%cp11$vectors[,1] cp2cov&lt;-as.matrix(aux1[,-2])%*%cp11$vectors[,2] plot(cp1cov,cp2cov) #8. Defina un indicador a partir de estos cor(cbind(aux1,cp1cov,cp2cov))[1:11,12:13] ## cp1cov cp2cov ## CC 0.92113465 0.35759774 ## FPV -0.08074887 -0.10802564 ## MTS -0.16786500 -0.30855895 ## UCS 0.14139049 -0.22216012 ## MAS - IPSP -0.92337643 0.36777758 ## 21F 0.32455320 -0.47209833 ## PDC -0.09883288 0.43937850 ## MNR 0.19561852 -0.25724983 ## PAN-BOL 0.04776390 -0.01901819 ## Blancos -0.17330606 -0.88168972 ## Nulos -0.08874645 0.06391096 bd&lt;-cbind(aux1,cp1cov,cp2cov) names(bd)[5]&lt;-&quot;MAS&quot; #9. Modele un modelo lineal empleando los CPs retenidos. summary(lm(MAS~cp1cov,data=bd)) ## ## Call: ## lm(formula = MAS ~ cp1cov, data = bd) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.39544 -0.05881 0.01417 0.06187 0.16168 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.3407735 0.0003141 1085.0 &lt;2e-16 *** ## cp1cov -0.7053686 0.0011240 -627.5 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.07868 on 68069 degrees of freedom ## Multiple R-squared: 0.8526, Adjusted R-squared: 0.8526 ## F-statistic: 3.938e+05 on 1 and 68069 DF, p-value: &lt; 2.2e-16 5.3 Análisis de correspondencia El analisis de correspondencia esta orientado a encontrar relaciones entre las categorias de variables cualitativas. Esta técnica es un método visual que va más alla del test de independencia Chi-cuadrado. Para resumir la teoría, primero divida la matriz de datos \\(I × J\\), denotada por \\(N\\), por su gran total \\(n\\) para obtener la llamada matriz de correspondencia \\(P = N / n\\). Deje que los totales marginales de fila y columna de \\(P\\) sean los vectores \\(r\\) y \\(c\\) respectivamente, es decir, los vectores de masas de fila y columna, y \\(Dr\\) y \\(Dc\\) sean las matrices diagonales de estas matrices. El algoritmo computacional para obtener coordenadas de los perfiles de fila y columna con respecto a los ejes principales, usando el SVD, es el siguiente: Calcular la matriz de residuos estadarizados: \\(S=D_r^{-1/2}(P-rc^t)D_c^{-1/2}\\) Calcular la descomposición SVD de \\(S\\): \\(S=UD_{\\alpha}V^t\\), donde \\(U^T U=V^T V=I\\) Coordenadas principales de filas: \\(F=D_r^{-1/2} U D_{\\alpha}\\) Coordenadas principales de columnas: \\(G=D_c^{-1/2} V D_{\\alpha}\\) Coordenadas estándar de filas: \\(X=D_r^{-1/2} U\\) Coordenadas estándar de columnas: \\(Y=D_c^{-1/2} V\\) Calcular la Inercia: \\[\\phi^2=\\sum_i^I\\sum_j^J{\\frac{(p_{ij}-r_i c_j)^2}{r_i c_j}}\\] Graficar las coordenadas de F y G según la la inercia contenida en la matriz \\(D_{\\alpha}\\) En R, existe la libreria ca que permite acceder a las coordenadas del método de correspondencia. #ejemplo CA #install.packages(&quot;ca&quot;) library(dplyr) library(ca) data(&quot;smoke&quot;) model&lt;-ca(smoke) plot(model) names(model) ## [1] &quot;sv&quot; &quot;nd&quot; &quot;rownames&quot; &quot;rowmass&quot; ## [5] &quot;rowdist&quot; &quot;rowinertia&quot; &quot;rowcoord&quot; &quot;rowsup&quot; ## [9] &quot;colnames&quot; &quot;colmass&quot; &quot;coldist&quot; &quot;colinertia&quot; ## [13] &quot;colcoord&quot; &quot;colsup&quot; &quot;N&quot; &quot;call&quot; summary(model) ## ## Principal inertias (eigenvalues): ## ## dim value % cum% scree plot ## 1 0.074759 87.8 87.8 ********************** ## 2 0.010017 11.8 99.5 *** ## 3 0.000414 0.5 100.0 ## -------- ----- ## Total: 0.085190 100.0 ## ## ## Rows: ## name mass qlt inr k=1 cor ctr k=2 cor ctr ## 1 | SM | 57 893 31 | -66 92 3 | -194 800 214 | ## 2 | JM | 93 991 139 | 259 526 84 | -243 465 551 | ## 3 | SE | 264 1000 450 | -381 999 512 | -11 1 3 | ## 4 | JE | 456 1000 308 | 233 942 331 | 58 58 152 | ## 5 | SC | 130 999 71 | -201 865 70 | 79 133 81 | ## ## Columns: ## name mass qlt inr k=1 cor ctr k=2 cor ctr ## 1 | none | 316 1000 577 | -393 994 654 | -30 6 29 | ## 2 | lght | 233 984 83 | 99 327 31 | 141 657 463 | ## 3 | medm | 321 983 148 | 196 982 166 | 7 1 2 | ## 4 | hevy | 130 995 192 | 294 684 150 | -198 310 506 | #ejemplo ENDSA load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/master/data/endsa.RData&quot;)) ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): strings not representable in native ## encoding will be translated to UTF-8 ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Sin educación&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Con educación primaria&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Con educación ## secundaria&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Con educación superior&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Más pobre&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Más rico&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;No conoce métodos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Conoce sólo métodos ## folkloricos&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Conoce sólo métodos ## tradicionales&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Conoce métodos modernos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Usa sólo métodos ## folkloricos&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Usa sólo métodos ## tradicionales&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Usa métodos modernos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Más de una ves&#39; cannot ## be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Sin educación&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Con educación primaria&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Con educación ## secundaria&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Con educación superior&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;No trabajó&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Profesionales, técnicos, ## jefes&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Tareas domésticas&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;No trabajó&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Profesionales, técnicos, ## jefes&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Tareas domésticas&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;El año pasado&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Todo el año&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Área&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Año&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Nivel de educación&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Años de educación en el ## ciclo&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Total de años de ## educación&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Mira televisión en la ## semana&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Índice de riqueza&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Conocimiento de algun ## método anticonceptivo&#39; cannot be translated to UTF-8, is it valid ## in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Uso de algún método ## anticonceptivo&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Método comunmente usado&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Edad al momento de ## la esterilización&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Edad a la primera ## relación sexual&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Número de uniones&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Total de niños nacidos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Mantendría en secreto si ## alguien de su familia tuviera tb&#39; cannot be translated to UTF-8, ## is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Número ideal de niños&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Número ideal de hijos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Número ideal de hijas&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Nivel de educación de la ## pareja&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Años de educación en el ## ciclo (de la pareja)&#39; cannot be translated to UTF-8, is it valid ## in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Ocupación de la pareja&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Educación en años ## simples de la pareja&#39; cannot be translated to UTF-8, is it valid ## in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Ocupación&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Trabajó en los ultimos ## 12 meses&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Quién decide como ## gastar el dinero?&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Factor de expansión&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Todo el año&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;El año pasado&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;No trabajó&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Profesionales, técnicos, ## jefes&#39; cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Tareas domésticas&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Más de una ves&#39; cannot ## be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Usa sólo métodos ## folkloricos&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Usa sólo métodos ## tradicionales&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Usa métodos modernos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;No conoce métodos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Conoce sólo métodos ## folkloricos&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Conoce sólo métodos ## tradicionales&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Conoce métodos modernos&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Más pobre&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Más rico&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Sin educación&#39; cannot be ## translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Con educación primaria&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/ ## raw/master/data/endsa.RData&quot;)): input string &#39;Con educación ## secundaria&#39; cannot be translated to UTF-8, is it valid in ## &#39;UTF-8&#39; ? ## Warning in load(url(&quot;https://github.com/AlvaroLimber/EST-384/raw/ ## master/data/endsa.RData&quot;)): input string &#39;Con educación superior&#39; ## cannot be translated to UTF-8, is it valid in &#39;UTF-8&#39; ? ll&lt;-attributes(endsa) ll$var.labels ## [1] &quot;Cluster&quot; ## [2] &quot;Departamento&quot; ## [3] &quot;Área&quot; ## [4] &quot;Año&quot; ## [5] &quot;Edad&quot; ## [6] &quot;Sexo&quot; ## [7] &quot;Nivel de educación&quot; ## [8] &quot;Años de educación en el ciclo&quot; ## [9] &quot;Total de años de educación&quot; ## [10] &quot;Alfabetismo&quot; ## [11] &quot;Lee periodicos o revistas en la semana?&quot; ## [12] &quot;Escucha radio en la semana&quot; ## [13] &quot;Mira televisión en la semana&quot; ## [14] &quot;Índice de riqueza&quot; ## [15] &quot;Fuma&quot; ## [16] &quot;Conocimiento de algun método anticonceptivo&quot; ## [17] &quot;Uso de algún método anticonceptivo&quot; ## [18] &quot;Conocimiento del periodo fertil&quot; ## [19] &quot;Método comunmente usado&quot; ## [20] &quot;Edad al momento de la esterilización&quot; ## [21] &quot;A oido del sida?&quot; ## [22] &quot;Conoce maneras de evitar el VIH SIDA&quot; ## [23] &quot;Estado civil actual&quot; ## [24] &quot;Edad al primer matrimonio&quot; ## [25] &quot;Edad a la primera relación sexual&quot; ## [26] &quot;Número de uniones&quot; ## [27] &quot;Total de niños nacidos&quot; ## [28] &quot;Hijos en casa&quot; ## [29] &quot;Hijas en casa&quot; ## [30] &quot;Hijos en otro lugar&quot; ## [31] &quot;Hijas en otro lugar&quot; ## [32] &quot;Hijos que han muerto&quot; ## [33] &quot;Hijas que han muerto&quot; ## [34] &quot;Edad al primer nacimiento&quot; ## [35] &quot;A oido hablar de la tuberculosis o tb&quot; ## [36] &quot;Mantendría en secreto si alguien de su familia tuviera tb&quot; ## [37] &quot;Número ideal de niños&quot; ## [38] &quot;Número ideal de hijos&quot; ## [39] &quot;Número ideal de hijas&quot; ## [40] &quot;Nivel de educación de la pareja&quot; ## [41] &quot;Años de educación en el ciclo (de la pareja)&quot; ## [42] &quot;Ocupación de la pareja&quot; ## [43] &quot;Actualmente trabaja?&quot; ## [44] &quot;Educación en años simples de la pareja&quot; ## [45] &quot;Ocupación&quot; ## [46] &quot;Trabajó en los ultimos 12 meses&quot; ## [47] &quot;Edad de la pareja&quot; ## [48] &quot;Regularidad del trabajo&quot; ## [49] &quot;Quién decide como gastar el dinero?&quot; ## [50] &quot;(Psi) Acusan de ser infiel&quot; ## [51] &quot;(Psi) Limitan contacto con su familia&quot; ## [52] &quot;(PSI) Expresiones ofensivas&quot; ## [53] &quot;(PSI) Amenaza con irse &quot; ## [54] &quot;(PSI) Amenaza con no cumplir responsabilidad economica&quot; ## [55] &quot;(Fis) Empujado jaloneado&quot; ## [56] &quot;(Fis) Golpeado con mano o pie&quot; ## [57] &quot;(Fis) Golpeado con objeto duro&quot; ## [58] &quot;(Fis) Tratado de estrangular&quot; ## [59] &quot;(Fis) Forzado a tener relaciones&quot; ## [60] &quot;&quot; ## [61] &quot;Factor de expansión&quot; t1&lt;-endsa %&gt;% filter(year==2008) %&gt;% select(7,14) %&gt;% table() t1&lt;-t1[1:4,] #test chi2 chisq.test(t1) ## ## Pearson&#39;s Chi-squared test ## ## data: t1 ## X-squared = 8367.8, df = 12, p-value &lt; 2.2e-16 model&lt;-ca(t1) model ## ## Principal inertias (eigenvalues): ## 1 2 3 ## Value 0.323708 0.038805 0.001415 ## Percentage 88.95% 10.66% 0.39% ## ## ## Rows: ## Sin educación Con educación primaria ## Mass 0.036794 0.397860 ## ChiDist 0.999518 0.564015 ## Inertia 0.036758 0.126564 ## Dim. 1 -1.589674 -0.986443 ## Dim. 2 1.986439 0.251096 ## Con educación secundaria Con educación superior ## Mass 0.366807 0.198539 ## ChiDist 0.326543 0.901890 ## Inertia 0.039113 0.161492 ## Dim. 1 0.406081 1.521130 ## Dim. 2 -1.168372 1.287294 ## ## ## Columns: ## Más pobre Pobre Clase media Rico Más rico ## Mass 0.168964 0.177837 0.198713 0.218066 0.236420 ## ChiDist 0.869550 0.471835 0.232894 0.323342 0.830339 ## Inertia 0.127757 0.039591 0.010778 0.022799 0.163003 ## Dim. 1 -1.460754 -0.818013 -0.185957 0.436418 1.413047 ## Dim. 2 1.281961 -0.168562 -1.053040 -1.037739 1.052869 plot(model) #programando el ca lcol&lt;-colnames(t1) lrow&lt;-rownames(t1) P&lt;-prop.table(t1) r&lt;-margin.table(P,1) c&lt;-margin.table(P,2) Dr&lt;-diag(r) Dc&lt;-diag(c) ##Paso 1 P-r%*%t(c) ## ae08 ## ae01 Más pobre Pobre Clase media ## Sin educación 0.012441006 0.002372467 -0.001657500 ## Con educación primaria 0.057509375 0.035321601 0.003921918 ## Con educación secundaria -0.038100566 -0.011824251 0.014659135 ## Con educación superior -0.031849815 -0.025869816 -0.016923553 ## ae08 ## ae01 Rico Más rico ## Sin educación -0.005240036 -0.007915937 ## Con educación primaria -0.027698479 -0.069054414 ## Con educación secundaria 0.028348987 0.006916695 ## Con educación superior 0.004589529 0.070053656 #error en las matriz diagonales Dr^(-0.5)%*%(P-r%*%t(c))%*% Dc^(-0.5) ## [,1] [,2] [,3] [,4] [,5] ## [1,] NaN NaN NaN NaN NaN ## [2,] NaN NaN NaN NaN NaN ## [3,] NaN NaN NaN NaN NaN ## [4,] NaN NaN NaN NaN NaN # corrigiendo el problema S&lt;-diag(r^(-0.5))%*%(P-r%*%t(c))%*% diag(c^(-0.5)) # 2 descomposición SVD svd(S) ## $d ## [1] 5.689533e-01 1.969900e-01 3.761651e-02 8.641056e-17 ## ## $u ## [,1] [,2] [,3] [,4] ## [1,] -0.3049268 0.3810330 0.8514926 0.1918171 ## [2,] -0.6222107 0.1583814 -0.4357855 0.6307616 ## [3,] 0.2459415 -0.7076197 0.2682905 0.6056462 ## [4,] 0.6777804 0.5735882 -0.1143309 0.4455768 ## ## $v ## [,1] [,2] [,3] [,4] ## [1,] -0.60044732 0.52695380 0.43904427 -0.4084045 ## [2,] -0.34496166 -0.07108381 -0.78620333 -0.3924945 ## [3,] -0.08289454 -0.46941592 0.04584658 -0.5165641 ## [4,] 0.20379664 -0.48459901 0.41307289 -0.4090435 ## [5,] 0.68706615 0.51193680 -0.12803642 -0.4949736 U&lt;-svd(S)$u V&lt;-svd(S)$v Da&lt;-diag(svd(S)$d) #verificando las propiedades U %*% t(U) ## [,1] [,2] [,3] [,4] ## [1,] 1.000000e+00 1.942890e-16 -8.326673e-17 -5.551115e-17 ## [2,] 1.942890e-16 1.000000e+00 -1.110223e-16 5.551115e-17 ## [3,] -8.326673e-17 -1.110223e-16 1.000000e+00 1.665335e-16 ## [4,] -5.551115e-17 5.551115e-17 1.665335e-16 1.000000e+00 t(V) %*% V ## [,1] [,2] [,3] [,4] ## [1,] 1.000000e+00 2.220446e-16 2.081668e-16 5.551115e-17 ## [2,] 2.220446e-16 1.000000e+00 2.914335e-16 5.551115e-17 ## [3,] 2.081668e-16 2.914335e-16 1.000000e+00 8.326673e-17 ## [4,] 5.551115e-17 5.551115e-17 8.326673e-17 1.000000e+00 U %*% Da %*% t(V) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0.1577867 0.02932932 -0.01938445 -0.05849955 -0.08487368 ## [2,] 0.2218072 0.13278970 0.01394827 -0.09403647 -0.22515639 ## [3,] -0.1530435 -0.04629605 0.05429710 0.10023611 0.02348755 ## [4,] -0.1738948 -0.13767657 -0.08520326 0.02205724 0.32334513 S ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0.1577867 0.02932932 -0.01938445 -0.05849955 -0.08487368 ## [2,] 0.2218072 0.13278970 0.01394827 -0.09403647 -0.22515639 ## [3,] -0.1530435 -0.04629605 0.05429710 0.10023611 0.02348755 ## [4,] -0.1738948 -0.13767657 -0.08520326 0.02205724 0.32334513 # 3 Coordenadas principales filas FF&lt;- diag(r^(-0.5)) %*% U %*% Da # 4 Coordenadas principales columnas G&lt;- diag(c^(-0.5)) %*% V %*% Da # 5 Coordenadas estandar filas X&lt;- diag(r^(-0.5)) %*% U # 6 Coordenadas estandar columnas Y&lt;- diag(c^(-0.5)) %*% V # 7 inercia sum(((P-r%*%t(c))**2)/(r%*%t(c))) ## [1] 0.3639279 #graficando xmin&lt;-min(c(FF[,1],G[,1])) xmax&lt;-max(c(FF[,1],G[,1])) ymin&lt;-min(c(FF[,2],G[,2])) ymax&lt;-max(c(FF[,2],G[,2])) plot(FF[,1],FF[,2],col=&quot;red&quot;,xlim=c(xmin,xmax)*1.5,ylim=c(ymin,ymax)*1.1) points(G[,1],G[,2],col=&quot;blue&quot;) abline(h=0,v=0,lty=2) #incluyendo el texto plot(FF[,1],FF[,2],xlim=c(xmin,xmax)*1.5,ylim=c(ymin,ymax)*1.1,type = &quot;n&quot;) text(FF[,1],FF[,2],labels = lrow,col=&quot;red&quot;,cex=0.7) text(G[,1],G[,2],labels = lcol,col=&quot;blue&quot;,cex=0.7) abline(h=0,v=0,lty=2) #incluyendo mas información plot(FF[,1],FF[,2],xlim=c(xmin,xmax)*1.5,ylim=c(ymin,ymax)*1.1,type = &quot;n&quot;) text(FF[,1],FF[,2],labels = lrow,col=&quot;red&quot;,cex=0.5+r*2) text(G[,1],G[,2],labels = lcol,col=&quot;blue&quot;,cex=0.5+c*2) abline(h=0,v=0,lty=2) #viendo solo una dimensión plot(rep(0,dim(FF)[1]),FF[,1],type = &quot;n&quot;, axes = F) axis(2) text(rep(0,dim(FF)[1]),FF[,1],labels = lrow,col=&quot;red&quot;,cex=0.5+r*2) text(rep(0,dim(G)[1]),G[,1],labels = lcol,col=&quot;blue&quot;,cex=0.5+c*2) abline(h=0,v=0,lty=2) "],
["clustering.html", "6 Clustering 6.1 Medidas de Disimilaridad 6.2 Métodos de clustering 6.3 K-center Clustering (no jerárquicos) 6.4 Cluster Jerárquico 6.5 Ejercicios", " 6 Clustering El clustering es un método cuyo objetivo es el de crear grupos en base a las relaciones multivariantes que existen en los datos, este método es un método previo a las técnicas de clasificación que existen. La base del clustering es la definición de la similaridad entre las filas. Similaridad es definida como una función de distancia entre un par de filas. Es importante distinguir la existencia de grupos naturales dentro de los datos, normalmente estos grupos son características naturales de las observaciones de interés. 6.1 Medidas de Disimilaridad Dado el objetivo del clustering, el aspecto mas importante dentro de estos métodos es utilizar de forma correcta la medida de (di)similaridad entre un para de casos dentro de la base de datos. La definición de las medidas de distancia es crucial para aplicar estos modelos. Funciones de distancia incorrecta pueden generar sesgos en los resultados y ser un problema para etapas posteriores de la mineria de datos. Debemos distinguir las funciones de distancia segun la naturaleza de las variables. Sean las filas \\(x\\) e \\(y\\) dentro de una base de datos, estos vectores tienen una dimensión \\(p\\), es decir, se observan \\(p\\) variables para las 2 observaciones. 6.1.1 Distancia Euclideana: Variables numéricas \\[d(x,y)=\\sqrt{\\sum_{i=1}^p{(x_i-y_i)^2}}\\] Donde los \\(x_i\\) y \\(_y_i\\) son los valores para la variable \\(i\\) de las observaciones \\(x\\) e \\(y\\). 6.1.2 Distancia Manhattan: \\(p\\) grande \\[d(x,y)=\\sum_{i=1}^p{|x_i-y_i|}\\] 6.1.3 Distancia Minkowski \\[d(x,y)=\\left(\\sum_{i=1}^p{|x_i-y_i|^d}\\right)^{1/d}\\] aux&lt;-matrix(rnorm(100),nrow=5) dist(aux) #euclideana ## 1 2 3 4 ## 2 6.436064 ## 3 5.967361 5.102903 ## 4 5.584452 6.017033 4.902613 ## 5 6.513146 5.949892 6.866950 6.514061 dist(aux, method=&quot;manhattan&quot;) ## 1 2 3 4 ## 2 25.62344 ## 3 20.15929 18.52792 ## 4 21.76512 22.01045 17.23092 ## 5 24.76007 20.33734 26.41551 22.75186 dist(aux, method=&quot;minkowski&quot;, p=3) ## 1 2 3 4 ## 2 4.178438 ## 3 4.230870 3.545378 ## 4 3.707071 4.215103 3.480107 ## 5 4.393813 4.446358 4.588352 4.601635 6.1.4 programando minkowski&lt;-function(x,y,d){ dd&lt;-(sum(abs(x-y)**d))**(1/d) return(dd) } minkowski(c(1,2,3),c(4,2,1),d=2) ## [1] 3.605551 x&lt;-c(1,2,3) y&lt;-c(4,2,1) sum(abs(x-y)) # manhattan ## [1] 5 sqrt(sum(abs(x-y)**2)) # euclideana ## [1] 3.605551 # la funcion de distancia distancia&lt;-function(bd,d=2){ nf&lt;-dim(bd)[1] DD&lt;-matrix(NA,nf-1,nf-1) colnames(DD)&lt;-1:(nf-1) rownames(DD)&lt;-2:nf for(i in 1:(nf-1)){ for(j in (i+1):nf){ DD[j-1,i]&lt;-minkowski(bd[i,],bd[j,],d) } } return(DD) } distancia(aux,d=2) ## 1 2 3 4 ## 2 6.436064 NA NA NA ## 3 5.967361 5.102903 NA NA ## 4 5.584452 6.017033 4.902613 NA ## 5 6.513146 5.949892 6.866950 6.514061 dist(aux) ## 1 2 3 4 ## 2 6.436064 ## 3 5.967361 5.102903 ## 4 5.584452 6.017033 4.902613 ## 5 6.513146 5.949892 6.866950 6.514061 6.1.5 Variables cualitativas Para las variables cualitativas se debe considerar los casos cuando estas son nominales y ordinales, distinguir tambien los casos de variables binarias. install.packages(&quot;vegan&quot;) library(vegan) 6.1.6 Datos mixtos Una de los mayores desafios es cuando las variables son mixtas, es decir cuantitativas y cualitativas. install.packages(&quot;cluster&quot;) library(cluster) 6.2 Métodos de clustering Partición (k-center) Jerárquicos (dendograma) Basados en densidad Basados en cuadrículas (grid) 6.3 K-center Clustering (no jerárquicos) Algoritmo Partición de las observaciones en \\(k\\) grupos, obtener el vector de promedios de cada grupo (centroides). Se puede trabajar con la media o la mediana. Para cada observación calcular las distancia euclideana a los centroides y reasignar lo observación en base a la menor distancia, recalcular los centroides en base a la reasignación de cada observación Repetir el paso 2 hasta que que ya no existan más reasignaciones bd&lt;-data.frame(x=rnorm(100),y=rnorm(100)) kmeans(bd,2) ## K-means clustering with 2 clusters of sizes 42, 58 ## ## Cluster means: ## x y ## 1 0.4538895 -0.9149836 ## 2 -0.4356570 0.4954252 ## ## Clustering vector: ## [1] 2 2 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 ## [31] 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 2 2 2 1 1 2 1 2 1 2 1 2 2 2 ## [61] 1 2 1 1 1 1 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 2 2 1 2 1 2 2 2 1 ## [91] 2 2 1 2 1 2 1 2 1 1 ## ## Within cluster sum of squares by cluster: ## [1] 48.01544 77.37179 ## (between_SS / total_SS = 35.1 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; ## [5] &quot;tot.withinss&quot; &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; ## [9] &quot;ifault&quot; Ejemplo: Implementar el algoritmo para el k-center, con la distancia de Minkowski y para la media y mediana. #Nota: La entrada de la funcion es un data frame kcenter&lt;-function(bd,k=3,d=2,tipo=&quot;media&quot;,seed=123456){ nf&lt;-dim(bd)[1] nc&lt;-dim(bd)[2] #paso1: asignar las k (nf&gt;=k) set.seed(seed) bd$k&lt;-sample(1:k,nf,replace=T) centroide&lt;-NULL for(i in 1:k){ if(tipo==&quot;media&quot;){ centroide&lt;-rbind(centroide,apply(bd[bd$k==i,],2, mean)) } else if(tipo==&quot;mediana&quot;){ centroide&lt;-rbind(centroide,apply(bd[bd$k==i,],2, median)) } } #paso2 (recalcular loo centroides al final) cc&lt;-1 while(cc!=0){ #paso3 cc&lt;-0 for(i in 1:nf){ auxd&lt;-NULL for(j in 1:k){ auxd&lt;-c(auxd,minkowski(bd[i,1:nc],centroide[j,1:nc],d=d)) } newk&lt;-which(auxd==min(auxd)) if(newk!=bd$k[i]){ bd$k[i] &lt;- newk cc&lt;-cc+1 } } centroide&lt;-NULL for(i in 1:k){ if(tipo==&quot;media&quot;){ centroide&lt;-rbind(centroide,apply(bd[bd$k==i,],2, mean)) } else if(tipo==&quot;mediana&quot;){ centroide&lt;-rbind(centroide,apply(bd[bd$k==i,],2, median)) } } } return(bd) } Pensar en un gráfico que permita ver como se asignaron los cluster bd&lt;-data.frame(x=rnorm(100),y=rnorm(100),z=rnorm(100)) kcenter(bd,k=4,d=1,tipo=&quot;mediana&quot;) ## x y z k ## 1 -0.76419491 0.500694616 1.43696298 4 ## 2 0.10151715 0.143467917 0.51116664 4 ## 3 -1.56435805 0.308784331 0.17008731 1 ## 4 -0.51599819 0.464239666 -1.16362792 3 ## 5 0.09514194 0.387755190 -0.75435085 3 ## 6 -0.37653939 1.088583177 -0.62344944 3 ## 7 -1.18896868 -0.512299867 -1.58556028 1 ## 8 -3.49361431 -0.005174875 0.30560307 1 ## 9 0.11249915 1.809830224 0.93153012 4 ## 10 0.19049734 0.273473809 2.03291922 4 ## 11 0.79628421 -0.928977204 -0.18689107 2 ## 12 1.36057428 2.809923815 0.47257969 2 ## 13 -0.75848603 -1.105316893 -0.46840271 1 ## 14 0.87273709 0.060938593 -0.20235021 2 ## 15 -1.07059556 -0.905958052 0.14082543 1 ## 16 0.33445515 -1.003640058 1.50412848 4 ## 17 1.36476202 -0.186466020 -0.80357331 2 ## 18 0.52596123 -0.965118632 0.51571183 2 ## 19 -1.04704816 1.211399279 -1.16560096 3 ## 20 -1.01992148 -1.360809246 0.50501178 1 ## 21 0.68833829 -0.754022618 0.60185533 2 ## 22 1.76418456 -0.476131208 -0.92407517 2 ## 23 -0.72139934 -0.276716888 1.10169112 4 ## 24 -0.45972313 -0.849553848 -0.18162087 1 ## 25 0.59273676 0.003097636 0.13582858 2 ## 26 -1.61288360 -0.356028648 0.40201573 1 ## 27 -0.58849298 -0.644604782 0.24131015 1 ## 28 0.48722057 -1.527933786 -0.26558600 2 ## 29 1.43295492 -0.803296997 1.02119770 2 ## 30 0.05506878 -0.195254871 -0.05325697 2 ## 31 0.39097884 0.075411336 0.90354980 4 ## 32 -2.08499341 0.360985226 -0.45388255 3 ## 33 0.21017953 -0.348478080 -1.26915211 3 ## 34 0.63200929 -1.117047136 -1.66396742 2 ## 35 0.30161092 -0.017919472 -0.39889631 2 ## 36 1.31073017 -0.367384392 -1.04013141 2 ## 37 -0.06332234 -0.123935050 0.44566261 4 ## 38 -1.03191013 -2.033985324 -0.31252782 1 ## 39 0.72575875 0.910152645 -0.25741788 2 ## 40 -0.49178966 -0.799092436 1.85965059 4 ## 41 0.97232352 -0.642730250 -0.91671015 2 ## 42 -0.60528903 0.886561699 0.92821633 4 ## 43 1.11287442 -0.624426400 0.85623896 2 ## 44 0.48863942 -0.494741464 0.02466125 2 ## 45 -1.85253408 -0.124898883 1.15776704 4 ## 46 0.77534911 0.391869631 0.70849220 4 ## 47 0.86648025 0.145814733 -1.12476780 2 ## 48 -1.02693634 0.244519577 1.80073927 4 ## 49 -2.78153548 0.097110622 -0.47746197 1 ## 50 1.24855927 -0.288479636 -0.47164137 2 ## 51 -1.03236966 0.151404792 -0.44707521 1 ## 52 -0.77245461 0.184899065 1.40706210 4 ## 53 -0.37635866 0.523095419 -0.45170529 3 ## 54 -0.79357781 0.518381145 0.01959340 3 ## 55 0.33838974 -0.874939796 -1.94719652 2 ## 56 0.64795772 -1.171314228 0.31792587 2 ## 57 -0.15984023 -0.511329877 -0.15336395 1 ## 58 -0.65930947 0.364163706 0.04107126 3 ## 59 2.59302729 -1.498233115 -0.15168658 2 ## 60 1.02796151 -1.625423794 0.54948333 2 ## 61 0.89007793 0.145029299 -0.77194421 2 ## 62 -0.90220145 -0.187418135 -0.52368596 1 ## 63 0.92899072 -0.221105297 -0.03949716 2 ## 64 -0.31333418 0.529262364 0.20023147 3 ## 65 -0.31839260 1.403227692 -0.73636473 3 ## 66 -1.07994263 -0.853136828 0.59607068 1 ## 67 -0.30545862 -0.329893958 1.19918905 4 ## 68 0.46590553 0.616432044 0.46996422 4 ## 69 -0.24471076 -1.178797393 -1.75062900 3 ## 70 -0.02377222 -0.784339245 0.16078557 2 ## 71 1.41884391 0.673892033 -0.15928354 2 ## 72 -0.18633756 -0.130778650 -1.69456267 3 ## 73 -1.05359031 0.612023189 -1.52622941 3 ## 74 -0.59046194 0.458580338 1.10043988 4 ## 75 -0.37689130 1.219996999 -1.03207353 3 ## 76 0.34057951 0.171966705 -0.74241613 3 ## 77 0.11470214 -0.743411422 -0.39798490 2 ## 78 0.46292406 0.416104428 -0.69593598 3 ## 79 1.05603829 -0.146652732 1.15503966 4 ## 80 0.65535610 -0.908344152 -0.27888796 2 ## 81 -0.44601123 -0.239525454 0.66989712 4 ## 82 1.44500581 -0.681795379 0.91905447 2 ## 83 -0.10427419 1.846307373 -1.29452920 3 ## 84 2.16831819 1.627671973 1.17467126 4 ## 85 -0.55031760 0.821164762 -0.87888462 3 ## 86 -0.80484040 0.111847628 1.24618458 4 ## 87 0.10226214 1.093470715 1.71382464 4 ## 88 -0.04702085 -0.036886566 0.15983393 4 ## 89 1.50536904 -0.777786977 1.34774017 2 ## 90 -0.29227819 -0.858014717 -0.42838955 1 ## 91 0.15177155 -1.774701321 -0.90169424 2 ## 92 0.30008779 -1.393526043 0.98465872 4 ## 93 0.52209345 -0.665664387 0.34392676 2 ## 94 -0.54947295 -1.566976459 1.00252754 4 ## 95 -0.14468887 -0.453208077 -1.76655322 3 ## 96 -1.93435264 0.048889608 -1.42952046 3 ## 97 -0.41007396 1.681160532 -0.06105228 3 ## 98 0.12183407 -0.046135516 -0.77348330 3 ## 99 -0.65962113 -0.905169817 1.96148776 4 ## 100 -0.90419921 0.053553963 0.30468742 1 6.3.1 Validación cluster La estructura de los cluster es aleatoria (¿funciona?) ¿Cómo definimos el valor de \\(K\\)? Silhouette coefficient: Se obtiene para la observación \\(i\\) el promedio de distancia a todos los objetos en el mismo cluster (\\(a_i\\)) Se obtiene para la observación \\(i\\) el promedio de distancia a todos los objetos de los otros clusters (\\(b_i\\)) Se define a \\(s_i\\) como el coeficiente, con un recorrido entre \\([-1,1]\\), para cada observación \\(i\\) \\[s_i=\\frac{b_i-a_i}{max(a_i,b_i)}\\] Idealmente se espera que \\(a_i &lt; b_i\\) y los \\(a_i\\) cercanos a \\(0\\). library(cluster) kk&lt;-kmeans(bd,3) s &lt;- silhouette(kk$cluster, dist(bd)) plot(s) #sobre la base IRIS data(&quot;iris&quot;) aux&lt;-kmeans(iris[,-5],3) s &lt;- silhouette(aux$cluster, dist(iris[,-5])) plot(s) Medoide: es el punto de datos que es “menos diferente” de todos los otros puntos de datos. A diferencia del centroide, el medoide tiene que ser uno de los puntos originales. pam(bd,k=3) ## Medoids: ## ID x y z ## [1,] 23 -0.7213993 -0.2767169 1.10169112 ## [2,] 44 0.4886394 -0.4947415 0.02466125 ## [3,] 85 -0.5503176 0.8211648 -0.87888462 ## Clustering vector: ## [1] 1 2 1 3 3 3 3 1 3 1 2 3 2 2 1 1 2 2 3 1 2 2 1 2 2 1 1 2 2 2 ## [31] 2 3 2 2 2 2 2 2 3 1 2 1 2 2 1 2 2 1 3 2 3 1 3 3 2 2 2 3 2 2 ## [61] 2 3 2 3 3 1 1 2 2 2 2 3 3 1 3 2 2 3 2 2 1 2 3 2 3 1 1 2 2 2 ## [91] 2 2 2 1 3 3 3 2 1 1 ## Objective function: ## build swap ## 1.175931 1.122877 ## ## Available components: ## [1] &quot;medoids&quot; &quot;id.med&quot; &quot;clustering&quot; &quot;objective&quot; ## [5] &quot;isolation&quot; &quot;clusinfo&quot; &quot;silinfo&quot; &quot;diss&quot; ## [9] &quot;call&quot; &quot;data&quot; kmeans(bd,3) ## K-means clustering with 3 clusters of sizes 35, 33, 32 ## ## Cluster means: ## x y z ## 1 0.9400501 -0.33766771 0.2184160 ## 2 -0.8354807 0.03308908 0.7454807 ## 3 -0.2943642 -0.06973008 -0.9463813 ## ## Clustering vector: ## [1] 2 2 2 3 3 3 3 2 2 2 1 1 3 1 2 1 1 1 3 2 1 1 2 3 1 2 2 1 1 1 ## [31] 1 2 3 3 3 1 2 3 1 2 1 2 1 1 2 1 3 2 2 1 3 2 3 2 3 1 3 2 1 1 ## [61] 1 3 1 2 3 2 2 1 3 1 1 3 3 2 3 3 3 3 1 1 2 1 3 1 3 2 2 2 1 3 ## [91] 3 1 1 2 3 3 2 3 2 2 ## ## Within cluster sum of squares by cluster: ## [1] 54.62417 54.10200 46.01723 ## (between_SS / total_SS = 41.0 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; ## [5] &quot;tot.withinss&quot; &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; ## [9] &quot;ifault&quot; ¿Cúal es el número óptimo de \\(k\\)? library(fpc)# Flexible Procedures for Clustering sol &lt;- pamk(iris[,-5], krange=2:10, criterion=&quot;asw&quot;, usepam=TRUE) sol ## $pamobject ## Medoids: ## ID Sepal.Length Sepal.Width Petal.Length Petal.Width ## [1,] 8 5.0 3.4 1.5 0.2 ## [2,] 127 6.2 2.8 4.8 1.8 ## Clustering vector: ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [31] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 ## [61] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [91] 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [121] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## Objective function: ## build swap ## 0.9901187 0.8622026 ## ## Available components: ## [1] &quot;medoids&quot; &quot;id.med&quot; &quot;clustering&quot; &quot;objective&quot; ## [5] &quot;isolation&quot; &quot;clusinfo&quot; &quot;silinfo&quot; &quot;diss&quot; ## [9] &quot;call&quot; &quot;data&quot; ## ## $nc ## [1] 2 ## ## $crit ## [1] 0.0000000 0.6857882 0.5528190 0.4896972 0.4867481 0.4703951 ## [7] 0.3390116 0.3318516 0.2918520 0.2918482 pamk(bd,krange=2:10,usepam = T) ## $pamobject ## Medoids: ## ID x y z ## [1,] 52 -0.7724546 0.1848991 1.4070621 ## [2,] 2 0.1015172 0.1434679 0.5111666 ## [3,] 32 -2.0849934 0.3609852 -0.4538826 ## [4,] 85 -0.5503176 0.8211648 -0.8788846 ## [5,] 95 -0.1446889 -0.4532081 -1.7665532 ## [6,] 12 1.3605743 2.8099238 0.4725797 ## [7,] 18 0.5259612 -0.9651186 0.5157118 ## [8,] 24 -0.4597231 -0.8495538 -0.1816209 ## [9,] 61 0.8900779 0.1450293 -0.7719442 ## [10,] 82 1.4450058 -0.6817954 0.9190545 ## Clustering vector: ## [1] 1 2 3 4 4 4 5 3 6 1 7 6 8 9 8 7 9 7 4 8 ## [21] 7 9 1 8 2 3 8 7 10 2 2 3 5 5 9 9 2 8 9 1 ## [41] 9 1 10 7 1 2 9 1 3 9 4 1 4 4 5 7 8 2 10 7 ## [61] 9 8 9 2 4 8 1 2 5 8 9 5 4 1 4 9 8 9 10 7 ## [81] 2 10 4 6 4 1 1 2 10 8 8 7 7 7 5 3 4 9 1 2 ## Objective function: ## build swap ## 0.7276150 0.6953005 ## ## Available components: ## [1] &quot;medoids&quot; &quot;id.med&quot; &quot;clustering&quot; &quot;objective&quot; ## [5] &quot;isolation&quot; &quot;clusinfo&quot; &quot;silinfo&quot; &quot;diss&quot; ## [9] &quot;call&quot; &quot;data&quot; ## ## $nc ## [1] 10 ## ## $crit ## [1] 0.0000000 0.2227991 0.2488104 0.2279918 0.2248988 0.2429045 ## [7] 0.2673102 0.2788586 0.2740618 0.2869799 6.3.2 Distancias para variables nominales (todas nominales) En este caso la mejor estrategia es llevar las variables con sus categorias a variables binarias. Existen múltiples medidas de distancia para variables binarias, muchas de estas medidas son aproximaciones a las medidas mas conocidas. Entre ellas: Sean las filas \\(i\\), \\(j\\) que contienen los valores binarios de las variables de estudio. Sea \\(A\\) el total de \\(1\\) que existe en \\(i\\), \\(B\\) el total de \\(1\\) que existe en \\(j\\) y sea \\(J\\) el total de casos en los que los \\(1\\) ocurren simultaneamente en \\(i\\) y \\(j\\). Euclideana \\[d_{ij}=\\sqrt{A+B-2J}\\] * Manhattan \\[d_{ij}=A+B-2J\\] * Bray \\[d_{ij}=\\frac{A+B-2J}{A+B}\\] Binomial \\[d_{ij}=log(2)(A+B-2J)\\] aux&lt;-rbind(c(0,0,0,0,1,1,1),c(1,0,1,0,0,1,1)) A&lt;-sum(aux[1,]) B&lt;-sum(aux[2,]) J&lt;-sum(apply(aux, 2, sum)==2) #euclideana sqrt(A+B-2*J) ## [1] 1.732051 #manhathan A+B-2*J ## [1] 3 #bray (A+B-2*J)/(A+B) ## [1] 0.4285714 #binomial log(2)*(A+B-2*J) ## [1] 2.079442 library(vegan) ## Loading required package: permute ## This is vegan 2.5-6 vegdist(aux,binary = T) ## 1 ## 2 0.4285714 vegdist(aux,binary = F) ## 1 ## 2 0.4285714 #una base de datos mas grandes set.seed(999) aux1&lt;-matrix(rbinom(200,1,0.4),nrow = 20) vegdist(aux1,method = &quot;binomial&quot;,binary = T) ## 1 2 3 4 5 6 ## 2 3.4657359 ## 3 3.4657359 2.7725887 ## 4 2.7725887 4.8520303 4.8520303 ## 5 4.1588831 3.4657359 4.8520303 2.7725887 ## 6 2.7725887 3.4657359 3.4657359 4.1588831 1.3862944 ## 7 3.4657359 2.7725887 2.7725887 2.0794415 3.4657359 4.8520303 ## 8 2.0794415 1.3862944 2.7725887 4.8520303 3.4657359 2.0794415 ## 9 2.7725887 3.4657359 4.8520303 4.1588831 2.7725887 1.3862944 ## 10 2.7725887 4.8520303 3.4657359 2.7725887 2.7725887 2.7725887 ## 11 3.4657359 2.7725887 4.1588831 3.4657359 4.8520303 4.8520303 ## 12 2.7725887 4.8520303 3.4657359 2.7725887 4.1588831 2.7725887 ## 13 4.1588831 4.8520303 3.4657359 2.7725887 2.7725887 2.7725887 ## 14 4.8520303 4.1588831 4.1588831 3.4657359 3.4657359 3.4657359 ## 15 1.3862944 3.4657359 2.0794415 2.7725887 4.1588831 2.7725887 ## 16 3.4657359 4.1588831 5.5451774 2.0794415 0.6931472 2.0794415 ## 17 3.4657359 2.7725887 4.1588831 3.4657359 3.4657359 3.4657359 ## 18 2.7725887 4.8520303 3.4657359 4.1588831 4.1588831 4.1588831 ## 19 3.4657359 4.1588831 1.3862944 4.8520303 3.4657359 2.0794415 ## 20 4.8520303 2.7725887 4.1588831 3.4657359 3.4657359 3.4657359 ## 7 8 9 10 11 12 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 4.1588831 ## 9 6.2383246 2.0794415 ## 10 3.4657359 3.4657359 2.7725887 ## 11 2.7725887 4.1588831 3.4657359 3.4657359 ## 12 3.4657359 4.8520303 2.7725887 2.7725887 2.0794415 ## 13 4.8520303 4.8520303 2.7725887 2.7725887 3.4657359 2.7725887 ## 14 4.1588831 4.1588831 2.0794415 2.0794415 2.7725887 2.0794415 ## 15 3.4657359 2.0794415 2.7725887 1.3862944 3.4657359 2.7725887 ## 16 4.1588831 4.1588831 2.0794415 2.0794415 4.1588831 3.4657359 ## 17 5.5451774 2.7725887 2.0794415 4.8520303 4.1588831 4.8520303 ## 18 3.4657359 4.8520303 4.1588831 2.7725887 3.4657359 2.7725887 ## 19 4.1588831 2.7725887 3.4657359 2.0794415 4.1588831 3.4657359 ## 20 4.1588831 4.1588831 2.0794415 3.4657359 1.3862944 2.0794415 ## 13 14 15 16 17 18 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 ## 10 ## 11 ## 12 ## 13 ## 14 3.4657359 ## 15 2.7725887 3.4657359 ## 16 2.0794415 2.7725887 3.4657359 ## 17 2.0794415 4.1588831 3.4657359 2.7725887 ## 18 4.1588831 3.4657359 4.1588831 3.4657359 4.8520303 ## 19 2.0794415 4.1588831 2.0794415 4.1588831 4.1588831 3.4657359 ## 20 2.0794415 1.3862944 3.4657359 2.7725887 2.7725887 4.8520303 ## 19 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 ## 10 ## 11 ## 12 ## 13 ## 14 ## 15 ## 16 ## 17 ## 18 ## 19 ## 20 4.1588831 dist(aux1) ## 1 2 3 4 5 6 7 ## 2 2.236068 ## 3 2.236068 2.000000 ## 4 2.000000 2.645751 2.645751 ## 5 2.449490 2.236068 2.645751 2.000000 ## 6 2.000000 2.236068 2.236068 2.449490 1.414214 ## 7 2.236068 2.000000 2.000000 1.732051 2.236068 2.645751 ## 8 1.732051 1.414214 2.000000 2.645751 2.236068 1.732051 2.449490 ## 9 2.000000 2.236068 2.645751 2.449490 2.000000 1.414214 3.000000 ## 10 2.000000 2.645751 2.236068 2.000000 2.000000 2.000000 2.236068 ## 11 2.236068 2.000000 2.449490 2.236068 2.645751 2.645751 2.000000 ## 12 2.000000 2.645751 2.236068 2.000000 2.449490 2.000000 2.236068 ## 13 2.449490 2.645751 2.236068 2.000000 2.000000 2.000000 2.645751 ## 14 2.645751 2.449490 2.449490 2.236068 2.236068 2.236068 2.449490 ## 15 1.414214 2.236068 1.732051 2.000000 2.449490 2.000000 2.236068 ## 16 2.236068 2.449490 2.828427 1.732051 1.000000 1.732051 2.449490 ## 17 2.236068 2.000000 2.449490 2.236068 2.236068 2.236068 2.828427 ## 18 2.000000 2.645751 2.236068 2.449490 2.449490 2.449490 2.236068 ## 19 2.236068 2.449490 1.414214 2.645751 2.236068 1.732051 2.449490 ## 20 2.645751 2.000000 2.449490 2.236068 2.236068 2.236068 2.449490 ## 8 9 10 11 12 13 14 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 1.732051 ## 10 2.236068 2.000000 ## 11 2.449490 2.236068 2.236068 ## 12 2.645751 2.000000 2.000000 1.732051 ## 13 2.645751 2.000000 2.000000 2.236068 2.000000 ## 14 2.449490 1.732051 1.732051 2.000000 1.732051 2.236068 ## 15 1.732051 2.000000 1.414214 2.236068 2.000000 2.000000 2.236068 ## 16 2.449490 1.732051 1.732051 2.449490 2.236068 1.732051 2.000000 ## 17 2.000000 1.732051 2.645751 2.449490 2.645751 1.732051 2.449490 ## 18 2.645751 2.449490 2.000000 2.236068 2.000000 2.449490 2.236068 ## 19 2.000000 2.236068 1.732051 2.449490 2.236068 1.732051 2.449490 ## 20 2.449490 1.732051 2.236068 1.414214 1.732051 1.732051 1.414214 ## 15 16 17 18 19 ## 2 ## 3 ## 4 ## 5 ## 6 ## 7 ## 8 ## 9 ## 10 ## 11 ## 12 ## 13 ## 14 ## 15 ## 16 2.236068 ## 17 2.236068 2.000000 ## 18 2.449490 2.236068 2.645751 ## 19 1.732051 2.449490 2.449490 2.236068 ## 20 2.236068 2.000000 2.000000 2.645751 2.449490 6.3.3 Distancias para variables mixtas (cuantitativas, nominales, ordinales) library(cluster) data(&quot;flower&quot;) str(flower) ## &#39;data.frame&#39;: 18 obs. of 8 variables: ## $ V1: Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 2 1 1 1 1 1 1 2 2 ... ## $ V2: Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 1 2 1 2 2 1 1 2 2 ... ## $ V3: Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 1 1 2 1 1 1 2 1 1 ... ## $ V4: Factor w/ 5 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 4 2 3 4 5 4 4 2 3 5 ... ## $ V5: Ord.factor w/ 3 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;: 3 1 3 2 2 3 3 2 1 2 ... ## $ V6: Ord.factor w/ 18 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;&lt;&quot;4&quot;&lt;..: 15 3 1 16 2 12 13 7 4 14 ... ## $ V7: num 25 150 150 125 20 50 40 100 25 100 ... ## $ V8: num 15 50 50 50 15 40 20 15 15 60 ... dd&lt;-daisy(flower,metric = &quot;gower&quot;) summary(dd) ## 153 dissimilarities, summarized : ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1418 0.3904 0.4829 0.4865 0.5865 0.8875 ## Metric : mixed ; Types = N, N, N, N, O, O, I, I ## Number of objects : 18 Ejercicios Busque funciones en R que permitan calcular los k-center para variables mixtas y medoides Crear una funcion k-center para variables mixtas y alternativas para incluir el medoide. 6.4 Cluster Jerárquico El objetivo es obtener una jerarquía de posibles soluciones que van desde un solo grupo a \\(n\\) grupos, donde \\(n\\) es el número de observaciones en el conjunto de datos. 6.4.1 Algoritmo (Johnson) Se inicia con \\(n\\) grupos y se genera una matriz de \\(nxn\\) de distancias, \\(D=\\{d_{ik}\\}\\) d &lt;- dist(scale(iris[,-5])) h &lt;- hclust(d) plot(h,hang=-0.1,labels=iris[[&quot;Species&quot;]],cex=0.5) clus3 &lt;- cutree(h, 3) plot(h,hang=-0.1,labels=iris[[&quot;Species&quot;]],cex=0.5) rect.hclust(h,k=3) Single linkage Complete linkage Average linkage 6.5 Ejercicios Pensar en un gráfico que permita ver como se asignaron los cluster Pensar en optimizar el código empleado para el k-center Hacer que la función desarrollada para el k-center retorne también los centroides Utilizando la base de datos de las elecciones del 20 de octubre, crear una base de datos a nivel municipal, aplicar el método k-center con medoides para los resultados a nivel municipal y terminar el \\(k\\) óptimo en un rango de \\(k=2:10\\) (Usar datos relativos). "],
["regresión.html", "7 Regresión 7.1 Regresión lineal 7.2 Probit y Logit", " 7 Regresión 7.1 Regresión lineal 7.2 Probit y Logit "],
["clasificación.html", "8 Clasificación 8.1 Arboles de decision 8.2 Naive Bayes", " 8 Clasificación 8.1 Arboles de decision 8.2 Naive Bayes "],
["minería-de-texto.html", "9 Minería de Texto 9.1 Recolección de texto 9.2 Nubes de palabras 9.3 Análisis de sentimiento 9.4 n-gramas y correlaciones", " 9 Minería de Texto 9.1 Recolección de texto 9.2 Nubes de palabras 9.3 Análisis de sentimiento 9.4 n-gramas y correlaciones "]
]

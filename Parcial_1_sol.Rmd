---
title: "Primer Parcial (30pts). Solucionario"
subtitle: "Programacion Estadística II"
author: "Lic. Alvaro Chirino Gutierrez"
date: "8/6/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Pregunta 1 (5pts).
  * Liste y comente las fases del descubrimiento del conocimiento en las bases de datos (KDD)
  
**Resp.**

  1. Selección: Identificar los datos de interés
  2. Preprocesado: Trabajar con la base
  3. Transformacion: Adecuar la base segun la naturaleza de las variables
  4. Mineria de datos: Aplicar el modelo adecuado según las necesidades
  5. Interpretacion/Evaluación: Evaluar los resultados, retroalimentación
  
  
  * Describa que es un warehouse
  
**Resp.** Es un almancen de datos que permite gestionar las bases de datos en su múltiples formatos

  * Describa la diferencia entre componentes principales y análisis de correspondencia
  
**Resp.** Componentes principales: Aplicación de la descomposición espectral para la transformacion de variables, Análisis de Correspondencia: Técnica gráfica que aplica una transformacion SVD a partir de una matriz de contingencias de variables cualitativas. 

  * Describa la diferencia entre k-center y los clusters jerárquicos
  
**Resp.** Los métodos k-center parten de un valor k prefijado, los métodos jerárquicos no requieren un valor previo de k.

  * En el proceso de imputar si una variable alcanza un índice influx alto, esto siginifica que: ¿esta variable es más útil para imputar otras variables?. Si, No, explique.
  
**Resp.** NO, el influx alto significa que dicha variable sera más facil de imputar.

## Pregunta 2 (5 pts):
Empleando la encuesta a hogares 2018, obtenga una tabla que contenga el porcentaje y total de hogares (expandido) por departamento y área, que tengan a algún miembro del hogar con diabetes ó hipertension arterial ó enfermedad del corazón.

```{r}
library(dplyr)
load(url("https://github.com/AlvaroLimber/EST-384/raw/master/data/eh18.Rdata"))
aux<-levels(eh18p$s04a_01a)
eh18p<-eh18p %>% mutate(diabetes=(s04a_01a==aux[1] | s04a_01b==aux[1]),corazon=(s04a_01a==aux[4] | s04a_01b==aux[4]),hiper=(s04a_01a==aux[10] | s04a_01b==aux[10]))
eh18p$diabetes<-(eh18p$diabetes==T); eh18p$diabetes[is.na(eh18p$diabetes)]<-F
eh18p$corazon<-(eh18p$corazon==T); eh18p$corazon[is.na(eh18p$corazon)]<-F
eh18p$hiper<-(eh18p$hiper==T); eh18p$hiper[is.na(eh18p$hiper)]<-F
eh18p$cronicas<-(eh18p$diabetes+eh18p$corazon+eh18p$hiper)
bd<-aggregate(eh18p[,461],by=eh18p[,c("folio","upm","factor","estrato","area","depto")],sum)
bd$cron<-(bd$x>0)
library(survey)
library(knitr)
sd1<-svydesign(~upm,strata=~estrato,weights = ~factor,data=bd)
t1<-svytable(~depto+area,design=sd1)
t2<-svytable(~depto+area+cron,design=sd1)

kable(addmargins(round(t2[,,2],0)),caption="Hogares con algún miembro con diabetes, enfermedades del corazón ó hipertensión. Por departamento y área")

kable(round((t2[,,2]/t1)*100,2),caption="% de hogares por departamento y área  con algún miembro con diabetes, enfermedades del corazón ó hipertensión.")
```


## Pregunta 3 (10 pts) 

  * PCA: Empleando la base de datos de la encuesta a hogares 2018, seleccione solo al jefe del hogar y calcule el PCA con las variables; mujer, edad, años de educación, horas trabajadas a la semana, ingreso laboral, ingreso no laboral, ingreso percapita del hogar. Identifique la cantidad de componentes a retener con el criterio de eigenvalores que superen la unidad. Calcule los componentes principales retenidos y grafique sus histogramas.
  
```{r}
bd<-eh18p %>% filter(s02a_05=="1.JEFE O JEFA DEL HOGAR")
bd<-bd %>% mutate(mujer=(bd$s02a_02=="2.Mujer")*1,edad=s02a_03)
xx<-c("mujer","edad","aestudio","tothrs","ylab","ynolab","yhogpc")
bd<-bd[,xx]
bd<-bd[complete.cases(bd),]#con valores completos
bdpca<-princomp(bd,cor=T)
#identificando a los eigenvalores superiores a la unidad
plot(bdpca)
abline(h=1)
comp<-bdpca$scores[,1:3]#componetes retenidos
par(mfrow=c(1,3))
hist(comp[,1])
hist(comp[,2])
hist(comp[,3])
```

  * CA: Empleando la base de datos de las ENDSA para el año 2008, para las 10 variables de violencia tranformar a binarias como (1=frecuentemente ó a veces 0=Nunca) y realizar el MCA para las 10 variables de violencia transformadas incluyendo la variable sexo. Comentar los resultados.

```{r,warning=F,message=F}
library(FactoMineR)
load(url("https://github.com/AlvaroLimber/EST-384/raw/master/data/endsa.RData"))
bd<-endsa %>% filter(year==2008) %>% select(sexo,vf01:vf04,vf06:vf10)
#no se incluye la variable vf05 debido a que solo se pregunta a mujeres
bd<-bd[complete.cases(bd),]#nos quedamos solo con los valores completos
ll<-levels(bd$vf01)
bd<-bd %>% mutate(v1=(vf01==ll[1] | vf01==ll[2]))
bd<-bd %>% mutate(v2=(vf02==ll[1] | vf02==ll[2]))
bd<-bd %>% mutate(v3=(vf03==ll[1] | vf03==ll[2]))
bd<-bd %>% mutate(v4=(vf04==ll[1] | vf04==ll[2]))
bd<-bd %>% mutate(v5=(vf06==ll[1] | vf06==ll[2]))
bd<-bd %>% mutate(v6=(vf07==ll[1] | vf07==ll[2]))
bd<-bd %>% mutate(v7=(vf08==ll[1] | vf08==ll[2]))
bd<-bd %>% mutate(v8=(vf09==ll[1] | vf09==ll[2]))
bd<-bd %>% mutate(v9=(vf10==ll[1] | vf10==ll[2]))
names(bd)[11:19]<-attributes(endsa)$var.labels[c(50:53,55:59)]
endsa_mca<-MCA(bd[,c(1,11:19)])
plot(endsa_mca)
```

## Pregunta 4 (10 pts) 

Clustering: Empleando la base de datos de las elecciones del 20 de octubre, aplique de forma separada para los municipios y los países, en términos relativos sin considerar los blanco y nulos:

```{r}
#preparando las base de datos
load(url("https://github.com/AlvaroLimber/EST-384/raw/master/data/oct20.RData"))
mun<-computo %>% filter(computo[,1]=="Bolivia" & computo[,12]=="Presidente y Vicepresidente")
ext<-computo %>% filter(computo[,1]!="Bolivia" & computo[,12]=="Presidente y Vicepresidente")
mun<-aggregate(mun[,14:22],mun[,c(3,6)],sum)
ext<-aggregate(ext[,14:22],ext[,1],sum)
mun[,3:11]<-prop.table(as.matrix(mun[,3:11]),1)
ext[,2:10]<-prop.table(as.matrix(ext[,2:10]),1)
```

  * El Cluster k-center, identifique el mejor valor de $k$ entre 2 al 10, el mejor centro; media, mediana o medoide, y la mejor distancia; euclideana, manhattan.

```{r}
library(cluster)
library(fpc)
#########################
#Funcion k-center
minkowski<-function(x,y,d){
  dd<-(sum(abs(x-y)**d))**(1/d)
  return(dd)
}
kcenter<-function(bd,k=3,d=2,tipo="media",seed=123456){
  nf<-dim(bd)[1];nc<-dim(bd)[2]
  #paso1: asignar las k (nf>=k)
  set.seed(seed)
  bd$k<-rep(seq(1:k),ceiling(nf/k))[1:nf]
  centroide<-NULL
  for(i in 1:k){
    if(tipo=="media"){  
      centroide<-rbind(centroide,apply(bd[bd$k==i,],2, mean))
    } else if(tipo=="mediana"){
      centroide<-rbind(centroide,apply(bd[bd$k==i,],2, median))
    }
  }
  #paso2 (recalcular los centroides al final)
  cc<-1
  while(cc!=0){ #paso3
    cc<-0
    for(i in 1:nf){
      auxd<-NULL
      for(j in 1:k){
        auxd<-c(auxd,minkowski(bd[i,1:nc],centroide[j,1:nc],d=d))
      }
      newk<-which(auxd==min(auxd))
        if(newk!=bd$k[i]){
          bd$k[i] <- newk
          cc<-cc+1
        }
    }
    centroide<-NULL
    for(i in 1:k){
      if(tipo=="media"){  
        centroide<-rbind(centroide,apply(bd[bd$k==i,],2, mean))
      } else if(tipo=="mediana"){
        centroide<-rbind(centroide,apply(bd[bd$k==i,],2, median))
      }
    }
  }
  return(bd$k)
}
#########################
mm<-c("medoide", "media", "median") # método
k<-2:10 # cantidad de cluster
dd<-c("manhattan","euclidean")
# matriz de resultados
res<-matrix(NA, nrow = 9,ncol=6)
rownames(res)<-k
colnames(res)<-paste(rep(mm,2),rep(dd,each=3))
###############################
#Base municipal
#medoide
for(i in k){
  for(j in 1:2){
    set.seed(i*j)
    aux<-pam(mun[,3:11],k=i,metric = dd[j])
    d<-dist(mun[,3:11],method = dd[j])
    c<-aux$clustering
    s<-silhouette(c,d)
    res[i-1,j+2*(j-1)]<-mean(s[,3])
  }
}
#media
for(i in k){
  for(j in 1:2){
    set.seed(i*j)
    c<-amap::Kmeans(mun[,3:11],centers = i,method = dd[j])$cluster
    #c<-kcenter(mun[,3:11],k=i)  
    d<-dist(mun[,3:11],method = dd[j])    
    s<-silhouette(c,d)
    res[i-1,1+j+2*(j-1)]<-mean(s[,3])
  }
}
#mediana
for(i in k){
  for(j in 1:2){
    c<-kcenter(mun[,3:11],k=i,d=j,tipo="mediana")  
    d<-dist(mun[,3:11],method = dd[j])    
    s<-silhouette(c,d)
    res[i-1,2+j+2*(j-1)]<-mean(s[,3])
  }
}
kable(res)
kable(res==max(res),caption="Base municipal, Mejor valor de k, k-center")
#################################################
#Base exterior
res<-matrix(NA, nrow = 9,ncol=6)
rownames(res)<-k
colnames(res)<-paste(rep(mm,2),rep(dd,each=3))
#medoide
for(i in k){
  for(j in 1:2){
    set.seed(i*j)
    aux<-pam(ext[,2:10],k=i,metric = dd[j])
    d<-dist(ext[,2:10],method = dd[j])
    c<-aux$clustering
    s<-silhouette(c,d)
    res[i-1,j+2*(j-1)]<-mean(s[,3])
  }
}
#media
for(i in k){
  for(j in 1:2){
    set.seed(i*j)
    c<-amap::Kmeans(ext[,2:10],centers = i,method = dd[j])$cluster
    #c<-kcenter(mun[,3:11],k=i)  
    d<-dist(ext[,2:10],method = dd[j])    
    s<-silhouette(c,d)
    res[i-1,1+j+2*(j-1)]<-mean(s[,3])
  }
}
#mediana
for(i in k){
  for(j in 1:2){
    c<-kcenter(ext[,2:10],d=j,k=i,tipo="mediana",seed=i*j)  
    d<-dist(ext[,2:10],method = dd[j])    
    s<-silhouette(c,d)
    res[i-1,2+j+2*(j-1)]<-mean(s[,3])
  }
}
kable(res)
kable(res==max(res),caption="Base exterior, Mejor valor de k, k-center")
```


  * El Cluster jerarquico, identifique el mejor valor de $k$ entre 2 al 10, el mejor método; complete, single, average y la mejor distancia; euclideana, manhattan
  
```{r}
library(cluster)
library(Gmedian)
#base municipio
# determinar el mejor k y el mejor enlace
mm<-c("single", "complete", "average") # método
k<-2:10 # cantidad de cluster
dd<-c("euclidean","manhattan")
# matriz de resultados
res<-matrix(NA, nrow = 9,ncol=6)
rownames(res)<-k
colnames(res)<-paste(rep(mm,2),rep(dd,each=3))
#######################
for(i in k){
  for(j in 1:3){
    for(m in 1:2){
      d<-dist(mun[,3:11],method = dd[m]) # matriz de distancia      
      h<-hclust(d,method = mm[j])
      c<-cutree(h,i)
      s<-silhouette(c,d)
      res[i-1,j+3*(m-1)]<-mean(s[,3])
    }
  }
}
kable(res)
kable(res==max(res),caption="Base municipal, Mejor valor de k, Jerarquico")
#base exterior
res<-matrix(NA, nrow = 9,ncol=6)
rownames(res)<-k
colnames(res)<-paste(rep(mm,2),rep(dd,each=3))
#######################
for(i in k){
  for(j in 1:3){
    for(m in 1:2){
      d<-dist(ext[,2:10],method = dd[m]) # matriz de distancia      
      h<-hclust(d,method = mm[j])
      c<-cutree(h,i)
      s<-silhouette(c,d)
      res[i-1,j+3*(m-1)]<-mean(s[,3])
    }
  }
}
kable(res)
kable(res==max(res),caption="Base exterior, Mejor valor de k, Jerarquico")
```


## Pregunta 5 (Opcional, 5 pts): 
Programe una función que calcule el coeficiente de silueta dada una matriz de distancias y un vector de identificación del cluster

```{r}
d<-dist(ext[,2:10])
c<-kmeans(ext[,2:10],3)$cluster
silueta<-function(d,c){
  d<-as.matrix(d)
  nf<-dim(d)[1]
  d<-cbind(d,c)
  s<-NULL;sR<-NULL
  for(i in 1:nf){
    cc<-d[i,"c"]
    #silueta R
    a<-mean(d[-i,i][d[-i,"c"]==cc])
    b<-min(tapply(d[d[,"c"]!=cc,i],d[d[,"c"]!=cc,"c"],mean))
    sR<-c(sR,(b-a)/max(a,b))
    #silueta libro
    aux<-tapply(d[-i,i],d[-i,"c"]==cc,mean)
    a<-as.numeric(aux[2])
    b<-as.numeric(aux[1])
    s<-c(s,(b-a)/max(a,b))
  }
  return(list(s=s,sR=sR))
}
silueta(d,c)
silhouette(c,d)
```

